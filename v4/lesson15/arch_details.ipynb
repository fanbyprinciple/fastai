{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arch_details",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "072b14620e024ba4bf25e9e580a049d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_28ae4195d9764687baa031ca0f8cce05",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6001805b4b08432bac08174a965e690d",
              "IPY_MODEL_ddddb5d23fdb46f2868d1d1f0e25a6a7"
            ]
          }
        },
        "28ae4195d9764687baa031ca0f8cce05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6001805b4b08432bac08174a965e690d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_484c26d7b2524e4cb9ce993ef087c239",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87306240,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87306240,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_523b00d0d5b244b58e1f08846515bdc2"
          }
        },
        "ddddb5d23fdb46f2868d1d1f0e25a6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d7fefb6b122840c6b18c6677edaea551",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 83.3M/83.3M [00:00&lt;00:00, 168MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_859c4ffbda9a4fa9a89a4f51559428eb"
          }
        },
        "484c26d7b2524e4cb9ce993ef087c239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "523b00d0d5b244b58e1f08846515bdc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7fefb6b122840c6b18c6677edaea551": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "859c4ffbda9a4fa9a89a4f51559428eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYq3cQcLYnys",
        "outputId": "0b3cf3be-6f60-49d9-b22d-526502900d1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 13.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 28.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 40kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 29.5MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sSska1QZBav"
      },
      "source": [
        "from fastbook import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4QSoVzSZdUx"
      },
      "source": [
        "## computer vision models\n",
        "\n",
        "### cnn_learner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfvYG5l0ZEhf",
        "outputId": "524b4004-7e3c-4569-f8c9-c613c3e45bd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_meta[resnet50]\n",
        "\n",
        "# when we pass the cnn_learner parameters we actully are defineing the body\n",
        "# the head we slice of  to train later"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cut': -2,\n",
              " 'split': <function fastai.vision.learner._resnet_split>,\n",
              " 'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "490hFkEJaOX6",
        "outputId": "80168d42-727a-4f45-9866-f9f6a5beb159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "create_head(20,2)\n",
        "\n",
        "# then we use the create_head function to create the head"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): AdaptiveConcatPool2d(\n",
              "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
              "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
              "  )\n",
              "  (1): Flatten(full=False)\n",
              "  (2): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (3): Dropout(p=0.25, inplace=False)\n",
              "  (4): Linear(in_features=20, out_features=512, bias=False)\n",
              "  (5): ReLU(inplace=True)\n",
              "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (7): Dropout(p=0.5, inplace=False)\n",
              "  (8): Linear(in_features=512, out_features=2, bias=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9j6BfCQdXJh"
      },
      "source": [
        "## unet_learner\n",
        "\n",
        "unet learner is used in many vision tasks like image segmentation like predicting on every pixel . This is done by first training the activations and then putting another neural network at the end such that it can be trained to give us a 224 pixel image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taO3xC-SdIos",
        "outputId": "c59a6fbc-722a-46ca-97b5-48724e32ee07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from fastai.vision.all import *\n",
        "path = untar_data(URLs.PETS)\n",
        "files = get_image_files(path/\"images\")\n",
        "\n",
        "class SiameseImage(fastuple):\n",
        "    def show(self, ctx=None, **kwargs): \n",
        "        img1,img2,same_breed = self\n",
        "        if not isinstance(img1, Tensor):\n",
        "            if img2.size != img1.size: img2 = img2.resize(img1.size)\n",
        "            t1,t2 = tensor(img1),tensor(img2)\n",
        "            t1,t2 = t1.permute(2,0,1),t2.permute(2,0,1)\n",
        "        else: t1,t2 = img1,img2\n",
        "        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n",
        "        return show_image(torch.cat([t1,line,t2], dim=2), \n",
        "                          title=same_breed, ctx=ctx)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0-73D-5m0pU"
      },
      "source": [
        "def label_func(fname):\n",
        "    return re.match(r'^(.*)_\\d+.jpg$', fname.name).groups()[0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU3QeZ0om-WQ"
      },
      "source": [
        "class SiameseTransform(Transform):\n",
        "    def __init__(self, files, label_func, splits):\n",
        "        self.labels = files.map(label_func).unique()\n",
        "        self.lbl2files = {l: L(f for f in files if label_func(f) == l) for l in self.labels}\n",
        "        self.label_func = label_func\n",
        "        self.valid = {f: self._draw(f) for f in files[splits[1]]}\n",
        "        \n",
        "    def encodes(self, f):\n",
        "        f2,t = self.valid.get(f, self._draw(f))\n",
        "        img1,img2 = PILImage.create(f),PILImage.create(f2)\n",
        "        return SiameseImage(img1, img2, t)\n",
        "    \n",
        "    def _draw(self, f):\n",
        "        same = random.random() < 0.5\n",
        "        cls = self.label_func(f)\n",
        "        if not same: cls = random.choice(L(l for l in self.labels if l != cls)) \n",
        "        return random.choice(self.lbl2files[cls]),same"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPl3gB3Mv5fh"
      },
      "source": [
        "splits = RandomSplitter()(files)\n",
        "tfm = SiameseTransform(files, label_func, splits)\n",
        "tls = TfmdLists(files, tfm, splits=splits)\n",
        "dls = tls.dataloaders(after_item=[Resize(224), ToTensor], \n",
        "    after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bENSkP8zyezD"
      },
      "source": [
        "Earlier we had built a dataset on true or false\n",
        "\n",
        "So we are now trying to build a custom model and train it. Using a pretrained architecture and passing out two images in it.\n",
        "\n",
        "we can then concatenate the results and send them to a custom head that will return two predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiqP80DkxkbL"
      },
      "source": [
        "class SiameseModel(Module):\n",
        "    def __init__(self, encoder, head):\n",
        "        self.encoder,self.head = encoder,head\n",
        "    \n",
        "    def forward(self, x1, x2):\n",
        "        ftrs = torch.cat([self.encoder(x1), self.encoder(x2)], dim=1)\n",
        "        return self.head(ftrs)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO26njlQzaOZ",
        "outputId": "7f775637-3907-4e80-ebe3-56471bb886b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "072b14620e024ba4bf25e9e580a049d1",
            "28ae4195d9764687baa031ca0f8cce05",
            "6001805b4b08432bac08174a965e690d",
            "ddddb5d23fdb46f2868d1d1f0e25a6a7",
            "484c26d7b2524e4cb9ce993ef087c239",
            "523b00d0d5b244b58e1f08846515bdc2",
            "d7fefb6b122840c6b18c6677edaea551",
            "859c4ffbda9a4fa9a89a4f51559428eb"
          ]
        }
      },
      "source": [
        "# taking a pretrained model and cutting it\n",
        "\n",
        "encoder = create_body(resnet34, cut=-2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "072b14620e024ba4bf25e9e580a049d1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVSWdsIJzpct"
      },
      "source": [
        "# now we create our head\n",
        "\n",
        "head = create_head(512*4, 2, ps=0.5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrTNifMKzyeO"
      },
      "source": [
        "model = SiameseModel(encoder, head)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc27rvh4z2pB"
      },
      "source": [
        "def loss_func(out, targ):\n",
        "    return nn.CrossEntropyLoss()(out, targ.long())"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKCKED6ez-S1"
      },
      "source": [
        "# splitter is a function that tells the fastai library how to split the model \n",
        "# when we do transfer learning\n",
        "def siamese_splitter(model):\n",
        "    return [params(model.encoder), params(model.head)]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtVkK2th1ZI8"
      },
      "source": [
        "learn = Learner(dls, model, loss_func=loss_func, \n",
        "                splitter=siamese_splitter, metrics=accuracy)\n",
        "learn.freeze()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPTHaAvk16er",
        "outputId": "ee8d1efe-50f7-469d-87da-dd1d20a67a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "learn.fit_one_cycle(4, 3e-3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.523156</td>\n",
              "      <td>0.335077</td>\n",
              "      <td>0.864682</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.361847</td>\n",
              "      <td>0.250744</td>\n",
              "      <td>0.901894</td>\n",
              "      <td>01:36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.278845</td>\n",
              "      <td>0.195504</td>\n",
              "      <td>0.928281</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.237074</td>\n",
              "      <td>0.175800</td>\n",
              "      <td>0.930988</td>\n",
              "      <td>01:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qq19bc1o5ynW"
      },
      "source": [
        "## moving to NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6QZeR_T6bYi"
      },
      "source": [
        "Converting an AWD-LSTM language model into a transfer learning classifier, as we did in <>, follows a very similar process to what we did with cnn_learner in the first section of this chapter.\n",
        "\n",
        "For this `for` loop we need to gather our data in batches, but each text needs to be treated separately, as they each have their own labels. However, it's very likely that those texts won't all be of the same length, which means we won't be able to put them all in the same array, like we did with the language model.\n",
        "\n",
        "That's where padding is going to help: when grabbing a bunch of texts, we determine the one with the greatest length, then we fill the ones that are shorter with a special token called `xxpad`. To avoid extreme cases where we have a text with 2,000 tokens in the same batch as a text with 10 tokens (so a lot of padding, and a lot of wasted computation), we alter the randomness by making sure texts of comparable size are put together. The texts will still be in a somewhat random order for the training set (for the validation set we can simply sort them by order of length), but not completely so.\n",
        "\n",
        "This is done automatically behind the scenes by the fastai library when creating our `DataLoaders`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRoIAEjy6k5d"
      },
      "source": [
        "## Tabular models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYNDLTzF6z2D"
      },
      "source": [
        " lets look at foraward method of tabular model\n",
        "\n",
        "```python\n",
        "if self.n_emb != 0:\n",
        "    x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
        "    x = torch.cat(x, 1)\n",
        "    x = self.emb_drop(x)\n",
        "if self.n_cont != 0:\n",
        "    x_cont = self.bn_cont(x_cont)\n",
        "    x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
        "return self.layers(x)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9ZDb5ig66LC"
      },
      "source": [
        "## Summary\n",
        "\n",
        "This chapter tells the missing links of createing our own model. Need to revisit other chapters to fully understand it`\n"
      ]
    }
  ]
}