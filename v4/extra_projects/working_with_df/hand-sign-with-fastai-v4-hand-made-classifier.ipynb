{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook is supposed to trace the chapter 4 for fastbook.\n\nHowever it is not easy for multilabel classification, using trivial model, therefore ill have to read chapter 6.\n\nSO will be back.`"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from fastai.vision.all import *\nimport pandas as pd","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Getting the data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = Path('../input/sign-language-mnist')\npath.ls()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"(#7) [Path('../input/sign-language-mnist/sign_mnist_test.csv'),Path('../input/sign-language-mnist/sign_mnist_test'),Path('../input/sign-language-mnist/sign_mnist_train'),Path('../input/sign-language-mnist/amer_sign2.png'),Path('../input/sign-language-mnist/amer_sign3.png'),Path('../input/sign-language-mnist/sign_mnist_train.csv'),Path('../input/sign-language-mnist/american_sign_language.PNG')]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN = path/'sign_mnist_train'/'sign_mnist_train.csv'","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST = path/'sign_mnist_test'/'sign_mnist_test.csv'","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(TRAIN)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      3     107     118     127     134     139     143     146     150   \n1      6     155     157     156     156     156     157     156     158   \n2      2     187     188     188     187     187     186     187     188   \n3      2     211     211     212     212     211     210     211     210   \n4     13     164     167     170     172     176     179     180     184   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0     153  ...       207       207       207       207       206       206   \n1     158  ...        69       149       128        87        94       163   \n2     187  ...       202       201       200       199       198       199   \n3     210  ...       235       234       233       231       230       226   \n4     185  ...        92       105       105       108       133       163   \n\n   pixel781  pixel782  pixel783  pixel784  \n0       206       204       203       202  \n1       175       103       135       149  \n2       198       195       194       195  \n3       225       222       229       163  \n4       157       163       164       179  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>107</td>\n      <td>118</td>\n      <td>127</td>\n      <td>134</td>\n      <td>139</td>\n      <td>143</td>\n      <td>146</td>\n      <td>150</td>\n      <td>153</td>\n      <td>...</td>\n      <td>207</td>\n      <td>207</td>\n      <td>207</td>\n      <td>207</td>\n      <td>206</td>\n      <td>206</td>\n      <td>206</td>\n      <td>204</td>\n      <td>203</td>\n      <td>202</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>155</td>\n      <td>157</td>\n      <td>156</td>\n      <td>156</td>\n      <td>156</td>\n      <td>157</td>\n      <td>156</td>\n      <td>158</td>\n      <td>158</td>\n      <td>...</td>\n      <td>69</td>\n      <td>149</td>\n      <td>128</td>\n      <td>87</td>\n      <td>94</td>\n      <td>163</td>\n      <td>175</td>\n      <td>103</td>\n      <td>135</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>187</td>\n      <td>188</td>\n      <td>188</td>\n      <td>187</td>\n      <td>187</td>\n      <td>186</td>\n      <td>187</td>\n      <td>188</td>\n      <td>187</td>\n      <td>...</td>\n      <td>202</td>\n      <td>201</td>\n      <td>200</td>\n      <td>199</td>\n      <td>198</td>\n      <td>199</td>\n      <td>198</td>\n      <td>195</td>\n      <td>194</td>\n      <td>195</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>211</td>\n      <td>211</td>\n      <td>212</td>\n      <td>212</td>\n      <td>211</td>\n      <td>210</td>\n      <td>211</td>\n      <td>210</td>\n      <td>210</td>\n      <td>...</td>\n      <td>235</td>\n      <td>234</td>\n      <td>233</td>\n      <td>231</td>\n      <td>230</td>\n      <td>226</td>\n      <td>225</td>\n      <td>222</td>\n      <td>229</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13</td>\n      <td>164</td>\n      <td>167</td>\n      <td>170</td>\n      <td>172</td>\n      <td>176</td>\n      <td>179</td>\n      <td>180</td>\n      <td>184</td>\n      <td>185</td>\n      <td>...</td>\n      <td>92</td>\n      <td>105</td>\n      <td>105</td>\n      <td>108</td>\n      <td>133</td>\n      <td>163</td>\n      <td>157</td>\n      <td>163</td>\n      <td>164</td>\n      <td>179</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.iloc[0]","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"label         3\npixel1      107\npixel2      118\npixel3      127\npixel4      134\n           ... \npixel780    206\npixel781    206\npixel782    204\npixel783    203\npixel784    202\nName: 0, Length: 785, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test\n#pd.DataFrame(tensor(train_df.iloc[0])).style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"getting labels and data from dataframe: https://www.kaggle.com/fanbyprinciple/kannada-mnist-fastai-pixel-to-image-conv"},{"metadata":{},"cell_type":"markdown","source":"### Trying to use datablock api"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_y(t_df):\n    return t_df['label'].to_numpy()\n\nget_y(train_df)\n\n# this works for y","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"array([ 3,  6,  2, ..., 18, 17, 23])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_x(t_df):\n    return t_df.drop('label',axis=1).to_numpy()\n\nget_x(train_df)","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array([[107, 118, 127, ..., 204, 203, 202],\n       [155, 157, 156, ..., 103, 135, 149],\n       [187, 188, 188, ..., 195, 194, 195],\n       ...,\n       [174, 174, 174, ..., 202, 200, 200],\n       [177, 181, 184, ...,  64,  87,  93],\n       [179, 180, 180, ..., 205, 209, 215]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Tensor from dataframe\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# note to self\n# can this be done without using the to_numpy()\n\n\n# using pytorch tensor function\n# hint: https://discuss.pytorch.org/t/how-to-convert-array-to-tensor/28809/7\n\n\ndef get_data_and_labels(data_frame, label):\n    labels = data_frame[label].to_numpy()\n    data = data_frame.drop([label], axis=1).to_numpy(dtype=np.float32).reshape((data_frame.shape[0], 28,28))\n    data = np.expand_dims(data, axis=1)\n    return data, labels","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data, train_labels = get_data_and_labels(train_df, 'label')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/raghuramr/mnist-by-beginner-with-fastai-resnet34\n\ndef get_images(df):\n    IMG_WIDTH = 28\n    IMG_HEIGHT = 28\n    \n    df['img'] = df[df.columns[df.columns.str.startswith('pixel')]].apply(\n        lambda x : PILImage(Image.fromarray(np.array(x.values).reshape((IMG_WIDTH, IMG_HEIGHT)).astype(np.uint8))),axis=1)\n    \n    return df[df.columns[[not x for x in df.columns.str.startswith('pixel')]]]","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_im = get_images(train_df)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_get_x(r): return r['img']\ndef new_get_y(r): return r['label']","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hands = DataBlock(blocks=(ImageBlock, CategoryBlock),\n                  get_x=new_get_x,\n                  get_y=new_get_y,\n                  splitter=RandomSplitter(seed=42),\n                  item_tfms = Resize(460),\n                  batch_tfms = aug_transforms(size=224, min_scale=0.75))\n\ntry:\n    hand_dls = hands.dataloaders(train_im) # hand_dls, get it ?\nexcept Exception as e:\n    print(e)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(hand_dls, resnet18, metrics=error_rate).to_fp16()\nlearn.fine_tune(2)","execution_count":null,"outputs":[{"output_type":"stream","text":"Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(TEST)\ntest_df['ImageId'] = test_df.index+1\ntest_df = get_images(test_df)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dl = learn.dls.test_dl(list(test_df['img']))\ninp, preds, _, dec_preds = learn.get_preds(dl=dl, with_input=True,with_decoded=True)\ntest_df['Label'] = dec_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test_df[['ImageId', 'Label']]\nsubmission.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_data[:5],train_labels[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show_image(train_data[7][0])\n# # \n# # image of 28 by 28","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(train_data), len(train_labels), train_data.shape, train_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.imshow(train_data[7,0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_labels[7]\n\n# # I was initially confused why not 3\n# # then I realised its sign language","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# np.random.seed(42)\n\n# # note to self\n# # use a splitter next time\n\n# # creating a validation set\n# ran_10_pct_idx = (np.random.random_sample(train_labels.shape)) < .1\n\n\n# train_90_labels = train_labels[np.invert(ran_10_pct_idx)]\n# train_90_data = train_data[np.invert(ran_10_pct_idx)]\n\n# valid_10_labels = train_labels[ran_10_pct_idx]\n# valid_10_data = train_data[ran_10_pct_idx]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### changing the shape of images"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_x = tensor(train_90_data).view(-1,28*28)\n\n# # to self\n# # calling tensor solves the error \"Type must be a sub-type of ndarray type\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_y = tensor(train_90_labels).unsqueeze(1)\n# #train_y = tensor(train_90_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# val_x = tensor(valid_10_data).view(-1,28*28)\n# val_y = tensor(valid_10_labels).unsqueeze(1)\n# #val_y = tensor(valid_10_labels)\n# val_x.shape, val_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a simple datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dset = list(zip(train_x, train_y))\n# valid_dset = list(zip(val_x, val_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# len(train_dset),len(valid_dset)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feeding dataset into dataloader"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dl = DataLoader(train_dset, batch_size=256)\n# val_dl = DataLoader( valid_dset, batch_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # lets test\n\n# xb, yb = first(dl)\n# xb.shape, yb.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# v_xb, v_yb = first(val_dl)\n# v_xb.shape, v_yb.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Starting simple : creating our own model\nwhich is not so simple tho"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # for weights and bias inititalisation\n# def init_params(size, std=1.0):\n#     return (torch.randn(size) * std).requires_grad_()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# weights = init_params((28*28,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# bias = init_params(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # trying on sample\n# (train_x[7]*weights.T).sum() + bias","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # defining the prediction function\n# def linear1(xb):\n#     return xb@weights+ bias","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets do it in a small batch"},{"metadata":{"trusted":true},"cell_type":"code","source":"# x, y =  train_dset[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# linear1(x), y\n\n# # there is no way that the linear1(x) value is equal to 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# inference on simple prediction function\n# preds = linear1(train_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now here i swhere things diverge\nSince instead of zero and one is spread of entire numerical range we will have to adjust our function for multi inputs rather than zero and one"},{"metadata":{"trusted":true},"cell_type":"code","source":"# corrects = (preds).float() == train_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corrects","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# corrects.float().mean().item()\n# # woah thats our accuracy right now!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so yes, direct equal to is not available. We need to find another parameter for loss.\nfrom : https://medium.com/@thevatsalsaglani/training-and-deploying-a-multi-label-image-classifier-using-pytorch-flask-reactjs-and-firebase-c39c96f9c427"},{"metadata":{"trusted":true},"cell_type":"code","source":"# def pred_acc(original, predicted):\n#     return torch.round(predicted).eq(original).sum().numpy()/len(original)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_acc(preds.float(), train_y.float())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We found that simple linear equation won't hold for working with fastai"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # will manually changing weights help ?\n# weights[2] *= 1.002\n# preds = linear1(train_x)\n# corrects = (preds>0.0).float() == train_y\n# corrects.float().mean().item()\n# # apparently nothing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def mnist_loss(predictions, targets):\n#     predictions = predictions.sigmoid()\n#     return torch.where(targets == 1, 1-predictions, predictions).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loss = mnist_loss(preds, train_y)\n# loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def calc_grad(xb, yb, model):\n#     preds = model(xb)\n#     loss = mnist_loss(preds, yb)\n#     loss.backward()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def train_epoch(model, lr, params,dl):\n#     for xb, yb in dl:\n#         calc_grad(xb, yb, model)\n#     # model is a function in this case linear1\n#         for p in params:\n#             p.data -= p.grad*lr\n#             p.grad.zero_()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def batch_accuracy(xb, yb):\n#     preds = xb.sigmoid()\n#     correct = (preds>0.5) == yb\n#     return correct.float().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def validate_epoch(model):\n#     accs = [batch_accuracy(model(xb),yb) for xb, yb in valid_dl]\n#     return round(torch.stack(accs).mean().item(), 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr = 1.\n# for i in range(30):\n#     train_epoch(linear1, lr, params, dl)\n#     print(validate_epoch(linear1), end=' ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # using dataloaders class\n\n# dls = DataLoaders(dl, val_dl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a custom architecture\nhttps://www.kaggle.com/fanbyprinciple/kannada-mnist-fastai-pixel-to-image-conv"},{"metadata":{"trusted":true},"cell_type":"code","source":"## TBD","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Learner class"},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn = Learner(dls, nn.Linear(28*28,1), loss_func=F.cross_entropy, metrics=accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.fit_one_cycle(42)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}