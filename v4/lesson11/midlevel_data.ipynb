{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midlevel_data",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFVNCenMHOZx",
        "outputId": "94894dfa-d28a-406e-d92e-c33b83a45840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_ffC97fDMlM"
      },
      "source": [
        "from IPython.display import display, HTML"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxCuY-qMFfB4"
      },
      "source": [
        "How to use mid level api to deal with data when Textblock api doesnt work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CRWpVzEDXln",
        "outputId": "841a519a-e39a-4efb-9f15-1f237fd92033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from fastai.text.all import *\n",
        "\n",
        "dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n",
        "\n",
        "# this works very weel with IMDB data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3lzSPGVHXxg"
      },
      "source": [
        "# we an also do that with DataBLock api\n",
        "\n",
        "path = untar_data(URLs.IMDB)\n",
        "dls = DataBlock(\n",
        "    blocks=(TextBlock.from_folder(path), CategoryBlock),\n",
        "    get_y = parent_label,\n",
        "    get_items = partial(get_text_files, folders=['train', 'test']),\n",
        "    splitter = GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "460tEOYIH8ow"
      },
      "source": [
        "But these might not be flexible enough. For debugging purposes wemight need to apply just parts of the transforms that with these datablocks. Or we might want to create a dataloaders not supported by fastai, we will dig into datablock api"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNinIKCRIvlG"
      },
      "source": [
        "### Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAz1q32WFxtk"
      },
      "source": [
        "files = get_text_files(path, folders=['train', 'test'])\n",
        "txts = L(o.open().read() for o in files[:2000])\n",
        "\n",
        "# we grabbed a bunch of texts"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djcpSgu5F05B",
        "outputId": "eb282067-f2e2-4ab8-cc2d-8d298e879cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tok = Tokenizer.from_folder(path)\n",
        "tok.setup(txts)\n",
        "toks = txts.map(tok)\n",
        "toks[0]\n",
        "\n",
        "# we tokenised them with tokenizer"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#68) ['xxbos','xxmaj','the','first','xxmaj','shiloh','film','was','enjoyable','by'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnoqiyxNJK3N",
        "outputId": "a3fe3369-f0f3-4e7e-9c15-33922d3e0d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks)\n",
        "nums = toks.map(num)\n",
        "nums[0][:10]\n",
        "\n",
        "# numericalize and creating automatic token for vocab of our corpus"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,    8,    9,  111,    8,    0,   33,   25, 1564,   55])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQwVybjIJn3N",
        "outputId": "8ca59db0-ad37-404b-8ec4-d354a6a618cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# classes have decode methods to give us the string tokens\n",
        "\n",
        "num_dec = num.decode(nums[0][:10])\n",
        "num_dec"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) ['xxbos','xxmaj','the','first','xxmaj','xxunk','film','was','enjoyable','by']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40GHlH0RJ14e",
        "outputId": "d8243e86-0c9f-49db-cc95-cd55110b2dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# getting tokenizer might be tricky as it might not be possible that\n",
        "# tokenizer is reversible\n",
        "\n",
        "tok.decode(num_dec)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxmaj the first xxmaj xxunk film was enjoyable by'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJkq8lOdLM-Y"
      },
      "source": [
        "Decoder is used by fastai show batch and show results\n",
        "to convert predictions and mini batches into a human understandable representation\n",
        "\n",
        "n general, a Transform is an object that behaves like a function and has an optional setup method that will initialize some inner state (like the vocab inside num) and an optional decode that will reverse the function (this reversal may not be perfect, as we saw with tok).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12wGobz9KFi6",
        "outputId": "1553001d-4c8d-4149-af63-55e84e5ad19a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tok((txts[0],txts[1]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((#68) ['xxbos','xxmaj','the','first','xxmaj','shiloh','film','was','enjoyable','by'...],\n",
              " (#371) ['xxbos','i','saw','this','film','when','it','first','came','out'...])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJEJKMByNY1_"
      },
      "source": [
        "### creating your own transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vswUMvEnM7y7",
        "outputId": "1290e6ac-7429-4aed-8c87-5043d3d95054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# transformer will onlty convert the object of same type\n",
        "\n",
        "def f(x:int): return x+1\n",
        "tfm = Transform(f)\n",
        "tfm(2), tfm(2.0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcyjhiiHNQMN",
        "outputId": "798e662f-d0b2-4fe4-dc13-a0fda261aace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# susing a decorator for passing a function to another function\n",
        "\n",
        "def f(x:int): return x+1\n",
        "f(2), f(2.0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpDymwvNNyM9",
        "outputId": "bfbe5818-f501-4247-9606-932141ebf38b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "@Transform\n",
        "def f(x:int): return x+1\n",
        "f(2), f(2.0)\n",
        "\n",
        "# 2.0 is rejected as it is float"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 2.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_9JPjVhN8yS"
      },
      "source": [
        "class NormalizeMean(Transform):\n",
        "  def setups(self, items):\n",
        "    self.mean = sum(items)/len(items)\n",
        "  def encodes(self, x):\n",
        "    return x-self.mean\n",
        "  def decodes(self, x):\n",
        "    return x+self.mean"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw5boNlbOiuo",
        "outputId": "fea4b253-c9c9-454c-d73d-c89303f27b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfm = NormalizeMean()\n",
        "tfm.setup([1,2,3,4,5])\n",
        "start = 2\n",
        "y = tfm(start)\n",
        "z = tfm.decode(y) # should be 2\n",
        "tfm.mean, y, z"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.0, -1.0, 2.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhCxEw9RPSdD"
      },
      "source": [
        "### Pipeline class\n",
        "\n",
        " to compose transforms together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv0Xjwh_POmm",
        "outputId": "f64e7747-f699-405a-d556-1a75a06cfeaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tfms = Pipeline([tok,num])\n",
        "t = tfms(txts[0])\n",
        "t[:20]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   2,    8,    9,  111,    8,    0,   33,   25, 1564,   55, 1907,   30,  104,   30,  516,   10,    8,   20,   44,  495])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-bRGNmbRn7B",
        "outputId": "f2f99193-f971-49a7-8a1c-37e7ef4e65e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tfms.decode(t)[:100]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxmaj the first xxmaj xxunk film was enjoyable by adults as well as children . xxmaj this one '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwa8NUxqRxlN"
      },
      "source": [
        "The only part that doesn't work the same way as in Transform is the setup. To properly set up a Pipeline of Transforms on some data, you need to use a TfmdLists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT2fOQKGRypZ"
      },
      "source": [
        "#TfmdLists and Datasets : Transformed Collections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VINDS1tERq-z"
      },
      "source": [
        "tls = TfmdLists(files, [Tokenizer.from_folder(path), Numericalize])\n",
        "\n",
        "#TfmdLists will automatically call the setup method of each transform order"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWSjehCPSACt",
        "outputId": "56528463-3497-4342-f8f1-c2b09ce7efb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t = tls[0]; t[:20]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,     8,     9,   107,     8, 36289,    32,    25,   756,    48,  1571,    27,    91,    27,   439,    10,     8,    20,    44,   530])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycJrjMR0SPlg",
        "outputId": "6d492831-5706-42a0-d078-90e4bc52bd19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "tls.decode(t)[:100]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxmaj the first xxmaj shiloh film was enjoyable by adults as well as children . xxmaj this one'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfKvKGHoSYSV",
        "outputId": "ab671e7f-071d-41f0-b289-64359945b850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# it also has a show method\n",
        "\n",
        "tls.show(t)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xxbos xxmaj the first xxmaj shiloh film was enjoyable by adults as well as children . xxmaj this one starts with about an hour of filler where not much happens , with stilted dialogue ; only in the last act is there any significant action that really moves the plot along . xxmaj the dog is still cute , though , and young kids may enjoy it .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7Sx2OORSxNH"
      },
      "source": [
        "The TfmdLists is named with an \"s\" because it can handle a training and a validation set with a splits argument"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTJ1Cf7CSdzh"
      },
      "source": [
        "cut = int(len(files)*0.8)\n",
        "splits = [list(range(cut)), list(range(cut,len(files)))]\n",
        "tls = TfmdLists(files, [Tokenizer.from_folder(path), Numericalize], \n",
        "                splits=splits)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Hp-NCcTDBE",
        "outputId": "7764799b-b272-49fe-8524-d34e7f89ea1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "splits[1][:5], splits[0][:5]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([40000, 40001, 40002, 40003, 40004], [0, 1, 2, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHOvi2_tTNtz",
        "outputId": "bd23b120-0e72-46bf-ec87-49862ac2a385",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cut"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HG1nAVvTSK9",
        "outputId": "7f7e7334-4377-4f51-b89a-87e1f679aa58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tls.valid[0][:20]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([    2,     8,    77,    29,     8,   365,    15,   875,    73,    12,   214,  1340,    54,     8,    64,     9,   173,    39,   138, 16708])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMBMJgCOUSX2"
      },
      "source": [
        "f you have manually written a Transform that performs all of your preprocessing at once, turning raw items into a tuple with inputs and targets, then TfmdLists is the class you need. You can directly convert it to a DataLoaders object with the dataloaders method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFXWAtlVTVik",
        "outputId": "72acc08a-59d6-4f64-9ac5-332e2794648d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lbls = files.map(parent_label)\n",
        "lbls\n",
        "\n",
        "# grabbing labels from parent folder"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#50000) ['neg','neg','neg','neg','neg','neg','neg','neg','neg','neg'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ier1zeQzVPPi",
        "outputId": "905cefcc-57cd-4fff-f0d5-70426ea6a40b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cat = Categorize()\n",
        "cat.setup(lbls)\n",
        "cat.vocab, cat(lbls[0])\n",
        "\n",
        "# building a covab ofunique items"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['neg', 'pos'], TensorCategory(0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W80kxSNaVqE0",
        "outputId": "46ba85f6-f155-464b-93aa-4e2475df6e15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# doing the whole setupthrough TfmdLists\n",
        "\n",
        "tls_y = TfmdLists(files, [parent_label, Categorize()])\n",
        "tls_y[0]\n",
        "\n",
        "# but we dont need seperate objects for inputs and targets thats why we use datasets"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorCategory(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NM-bpzWWEMz"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SonFnToV44y",
        "outputId": "44f2c39f-b3b9-4e3a-b984-d90801324562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_tfms = [Tokenizer.from_folder(path),Numericalize]\n",
        "y_tfms = [parent_label,Categorize()]\n",
        "dsets = Datasets(files, [x_tfms, y_tfms], splits=splits)\n",
        "x,y = dsets.valid[0]\n",
        "x[:20],y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    2,     8,    77,    29,     8,   365,    15,   875,    73,    12,   214,  1340,    54,     8,    64,     9,   173,    39,   138, 16708]),\n",
              " TensorCategory(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx3yhKrjV70-",
        "outputId": "942c344e-2e75-44b7-c6b1-018ad1ddaa20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_tfms = [Tokenizer.from_folder(path), Numericalize]\n",
        "y_tfms = [parent_label, Categorize()]\n",
        "dsets = Datasets(files, [x_tfms, y_tfms], splits=splits)\n",
        "x,y = dsets.valid[0]\n",
        "x[:20],y"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([    2,     8,    77,    29,     8,   365,    15,   875,    73,    12,   214,  1340,    54,     8,    64,     9,   173,    39,   138, 16708]),\n",
              " TensorCategory(1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWx1K157fWqO",
        "outputId": "930c8f33-b6aa-4fde-9bf2-af94a5cd5c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t = dsets.valid[0]\n",
        "dsets.decode(t)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"xxbos xxmaj time for xxmaj hollywood to sit up and take notice ! xxmaj if the actors are acting snooty , all you need to do is get the animators who worked on this little marvel . xxmaj renaissance is probably the first animation flick which makes you forget that you are not seeing human beings . xxmaj although the voice overs by the cast ( craig , mccormack , xxmaj pryce etc . ) are some of the best i have ever heard but even then the emotions portrayed by the ' cartoons ' are unnerving . \\n\\n xxmaj this style of animation is not very new but the use of light and shadows makes the movie a living painting . xxmaj ironically , such technical wizardry makes you forget that this is actually a very very nice movie . xxmaj the pacing and plot development are marvelous and the dialogs crisp . \\n\\n xxmaj plot : xxmaj disappearance of a mega corporation 's top employee unravels a tale of deceit and corruption with a xxmaj cold hearted hero at the helm . xxmaj ca n't say much without giving it all away â€¦ except that while the movie keeps you at the edge of your seat , the climax leaves you speechless . \\n\\n a must watch .. even for the ' grown - ups ' who smirk at ' cartoons '\",\n",
              " 'pos')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tim9-sbqfslD"
      },
      "source": [
        "# last step iscalling dataloaders\n",
        "dls = dsets.dataloaders(bs=64, before_batch=pad_input)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydER8C3phBai"
      },
      "source": [
        "Here the full code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYl21L_OgBb8"
      },
      "source": [
        "tfms = [[Tokenizer.from_folder(path), Numericalize], [parent_label,Categorize]]\n",
        "files = get_text_files(path, folders=['train', 'test'])\n",
        "splits = GrandparentSplitter(valid_name='test')(files)\n",
        "dsets = Datasets(files, tfms, splits=splits)\n",
        "dls = dsets.dataloaders(dl_type=SortedDL, before_batch=pad_input)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvrCjjc9hq5z"
      },
      "source": [
        "# which is same as the above \n",
        "\n",
        "path = untar_data(URLs.IMDB)\n",
        "dls = DataBlock(\n",
        "    blocks=(TextBlock.from_folder(path),CategoryBlock),\n",
        "    get_y = parent_label,\n",
        "    get_items=partial(get_text_files, folders=['train', 'test']),\n",
        "    splitter=GrandparentSplitter(valid_name='test')\n",
        ").dataloaders(path)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnsSoyAOh37D",
        "outputId": "c358bb72-1380-445d-ac4e-761234b36765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "dls.show_batch()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules of the match , both opponents have to go through tables in order to get the win . xxmaj benoit and xxmaj guerrero heated up early on by taking turns hammering first xxmaj spike and then xxmaj bubba xxmaj ray . a xxmaj german xxunk by xxmaj benoit to xxmaj bubba took the wind out of the xxmaj dudley brother . xxmaj spike tried to help his brother , but the referee restrained him while xxmaj benoit and xxmaj guerrero</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad xxpad</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}