{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Fast ai v4 on Rosemann\n\nDone upto datacleaning."},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.basics import *","execution_count":58,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":59,"outputs":[{"output_type":"stream","text":"/kaggle/input/rossmann-store-sales/sample_submission.csv\n/kaggle/input/rossmann-store-sales/store.csv\n/kaggle/input/rossmann-store-sales/test.csv\n/kaggle/input/rossmann-store-sales/train.csv\n/kaggle/input/rossmann/sample_submission.csv\n/kaggle/input/rossmann/store_states.csv\n/kaggle/input/rossmann/state_names.csv\n/kaggle/input/rossmann/weather.csv\n/kaggle/input/rossmann/store.csv\n/kaggle/input/rossmann/googletrend.csv\n/kaggle/input/rossmann/rossmann (1).tgz\n/kaggle/input/rossmann/test.csv\n/kaggle/input/rossmann/train.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Getting the data together\n\nThe extra data from rossmann one has to add to ones notebook.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = Config().data_path()/Path('rossmann/')","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!mkdir {PATH}\n#mkdir: cannot create directory ‘/root/.fastai/data/rossmann’: No such file or directory\n!mkdir /root/.fastai/data/\n!mkdir /root/.fastai/data/rossmann","execution_count":61,"outputs":[{"output_type":"stream","text":"mkdir: cannot create directory ‘/root/.fastai/data/’: File exists\nmkdir: cannot create directory ‘/root/.fastai/data/rossmann’: File exists\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /kaggle/input/rossmann/*.csv {PATH}","execution_count":62,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"table_names = ['train', 'store', 'store_states', 'state_names', 'googletrend', 'weather', 'test']","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tables = [pd.read_csv(PATH/f'{fname}.csv', low_memory=False) for fname in table_names]\ntrain, store, store_states, state_names, googletrend, weather, test = tables\ngoogletrend.tail()","execution_count":64,"outputs":[{"output_type":"execute_result","execution_count":64,"data":{"text/plain":"                file                     week  trend\n2067  Rossmann_DE_SL  2015-08-30 - 2015-09-05     95\n2068  Rossmann_DE_SL  2015-09-06 - 2015-09-12     47\n2069  Rossmann_DE_SL  2015-09-13 - 2015-09-19     80\n2070  Rossmann_DE_SL  2015-09-20 - 2015-09-26     57\n2071  Rossmann_DE_SL  2015-09-27 - 2015-10-03      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>week</th>\n      <th>trend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2067</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-08-30 - 2015-09-05</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2068</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-06 - 2015-09-12</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>2069</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-13 - 2015-09-19</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>2070</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-20 - 2015-09-26</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>2071</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-27 - 2015-10-03</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n0      1         c          a               1270.0                        9.0   \n1      2         a          a                570.0                       11.0   \n2      3         a          a              14130.0                       12.0   \n3      4         c          c                620.0                        9.0   \n4      5         a          a              29910.0                        4.0   \n\n   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n0                    2008.0       0              NaN              NaN   \n1                    2007.0       1             13.0           2010.0   \n2                    2006.0       1             14.0           2011.0   \n3                    2009.0       0              NaN              NaN   \n4                    2015.0       0              NaN              NaN   \n\n     PromoInterval  \n0              NaN  \n1  Jan,Apr,Jul,Oct  \n2  Jan,Apr,Jul,Oct  \n3              NaN  \n4              NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>StoreType</th>\n      <th>Assortment</th>\n      <th>CompetitionDistance</th>\n      <th>CompetitionOpenSinceMonth</th>\n      <th>CompetitionOpenSinceYear</th>\n      <th>Promo2</th>\n      <th>Promo2SinceWeek</th>\n      <th>Promo2SinceYear</th>\n      <th>PromoInterval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>c</td>\n      <td>a</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>a</td>\n      <td>a</td>\n      <td>570.0</td>\n      <td>11.0</td>\n      <td>2007.0</td>\n      <td>1</td>\n      <td>13.0</td>\n      <td>2010.0</td>\n      <td>Jan,Apr,Jul,Oct</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>a</td>\n      <td>a</td>\n      <td>14130.0</td>\n      <td>12.0</td>\n      <td>2006.0</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>2011.0</td>\n      <td>Jan,Apr,Jul,Oct</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>c</td>\n      <td>c</td>\n      <td>620.0</td>\n      <td>9.0</td>\n      <td>2009.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>a</td>\n      <td>a</td>\n      <td>29910.0</td>\n      <td>4.0</td>\n      <td>2015.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_states.head()","execution_count":66,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":"   Store State\n0      1    HE\n1      2    TH\n2      3    NW\n3      4    BE\n4      5    SN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>HE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>TH</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>BE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>SN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather.tail()","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"           file        Date  Max_TemperatureC  Mean_TemperatureC  \\\n15835  Saarland  2015-09-13                21                 17   \n15836  Saarland  2015-09-14                18                 14   \n15837  Saarland  2015-09-15                16                 12   \n15838  Saarland  2015-09-16                19                 15   \n15839  Saarland  2015-09-17                14                 13   \n\n       Min_TemperatureC  Dew_PointC  MeanDew_PointC  Min_DewpointC  \\\n15835                12          16              14             12   \n15836                11          15              12              7   \n15837                 9          11               8              7   \n15838                11          16              13             10   \n15839                12          14              12             10   \n\n       Max_Humidity  Mean_Humidity  ...  Max_VisibilityKm  Mean_VisibilityKm  \\\n15835           100             88  ...              31.0               15.0   \n15836            99             85  ...              31.0               13.0   \n15837            93             77  ...              31.0               12.0   \n15838            97             90  ...              31.0               10.0   \n15839            99             92  ...              31.0               14.0   \n\n       Min_VisibilitykM  Max_Wind_SpeedKm_h  Mean_Wind_SpeedKm_h  \\\n15835              10.0                  27                   10   \n15836               4.0                  32                   16   \n15837              10.0                  34                   14   \n15838               4.0                  32                   14   \n15839               8.0                  27                   16   \n\n       Max_Gust_SpeedKm_h  Precipitationmm  CloudCover             Events  \\\n15835                50.0             1.02         7.0               Rain   \n15836                53.0             9.91         5.0  Rain-Thunderstorm   \n15837                 NaN             0.00         5.0               Rain   \n15838                45.0            20.07         7.0  Rain-Thunderstorm   \n15839                47.0             6.10         6.0               Rain   \n\n       WindDirDegrees  \n15835             113  \n15836             213  \n15837             193  \n15838             147  \n15839             202  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>Date</th>\n      <th>Max_TemperatureC</th>\n      <th>Mean_TemperatureC</th>\n      <th>Min_TemperatureC</th>\n      <th>Dew_PointC</th>\n      <th>MeanDew_PointC</th>\n      <th>Min_DewpointC</th>\n      <th>Max_Humidity</th>\n      <th>Mean_Humidity</th>\n      <th>...</th>\n      <th>Max_VisibilityKm</th>\n      <th>Mean_VisibilityKm</th>\n      <th>Min_VisibilitykM</th>\n      <th>Max_Wind_SpeedKm_h</th>\n      <th>Mean_Wind_SpeedKm_h</th>\n      <th>Max_Gust_SpeedKm_h</th>\n      <th>Precipitationmm</th>\n      <th>CloudCover</th>\n      <th>Events</th>\n      <th>WindDirDegrees</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15835</th>\n      <td>Saarland</td>\n      <td>2015-09-13</td>\n      <td>21</td>\n      <td>17</td>\n      <td>12</td>\n      <td>16</td>\n      <td>14</td>\n      <td>12</td>\n      <td>100</td>\n      <td>88</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>15.0</td>\n      <td>10.0</td>\n      <td>27</td>\n      <td>10</td>\n      <td>50.0</td>\n      <td>1.02</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>15836</th>\n      <td>Saarland</td>\n      <td>2015-09-14</td>\n      <td>18</td>\n      <td>14</td>\n      <td>11</td>\n      <td>15</td>\n      <td>12</td>\n      <td>7</td>\n      <td>99</td>\n      <td>85</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>13.0</td>\n      <td>4.0</td>\n      <td>32</td>\n      <td>16</td>\n      <td>53.0</td>\n      <td>9.91</td>\n      <td>5.0</td>\n      <td>Rain-Thunderstorm</td>\n      <td>213</td>\n    </tr>\n    <tr>\n      <th>15837</th>\n      <td>Saarland</td>\n      <td>2015-09-15</td>\n      <td>16</td>\n      <td>12</td>\n      <td>9</td>\n      <td>11</td>\n      <td>8</td>\n      <td>7</td>\n      <td>93</td>\n      <td>77</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>34</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>5.0</td>\n      <td>Rain</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>15838</th>\n      <td>Saarland</td>\n      <td>2015-09-16</td>\n      <td>19</td>\n      <td>15</td>\n      <td>11</td>\n      <td>16</td>\n      <td>13</td>\n      <td>10</td>\n      <td>97</td>\n      <td>90</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>32</td>\n      <td>14</td>\n      <td>45.0</td>\n      <td>20.07</td>\n      <td>7.0</td>\n      <td>Rain-Thunderstorm</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>15839</th>\n      <td>Saarland</td>\n      <td>2015-09-17</td>\n      <td>14</td>\n      <td>13</td>\n      <td>12</td>\n      <td>14</td>\n      <td>12</td>\n      <td>10</td>\n      <td>99</td>\n      <td>92</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>14.0</td>\n      <td>8.0</td>\n      <td>27</td>\n      <td>16</td>\n      <td>47.0</td>\n      <td>6.10</td>\n      <td>6.0</td>\n      <td>Rain</td>\n      <td>202</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{},"cell_type":"markdown","source":"1. turning holidays into booleans to make the more convenient for modelling."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.StateHoliday = train.StateHoliday != '0'\ntest.StateHoliday = test.StateHoliday != '0'","execution_count":69,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. creating a custom join_df function for joining tables on specific fields"},{"metadata":{"trusted":true},"cell_type":"code","source":"def join_df(left, right, left_on, right_on=None, suffix='_y'):\n    if(right_on is None):\n        right_on = left_on\n    return left.merge(right, how='left', left_on=left_on, right_on=right_on, suffixes=(\"\", suffix))","execution_count":70,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. joining weather and state_names"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather = join_df(weather, state_names, \"file\", \"StateName\" )","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather.head()","execution_count":72,"outputs":[{"output_type":"execute_result","execution_count":72,"data":{"text/plain":"                 file        Date  Max_TemperatureC  Mean_TemperatureC  \\\n0  NordrheinWestfalen  2013-01-01                 8                  4   \n1  NordrheinWestfalen  2013-01-02                 7                  4   \n2  NordrheinWestfalen  2013-01-03                11                  8   \n3  NordrheinWestfalen  2013-01-04                 9                  9   \n4  NordrheinWestfalen  2013-01-05                 8                  8   \n\n   Min_TemperatureC  Dew_PointC  MeanDew_PointC  Min_DewpointC  Max_Humidity  \\\n0                 2           7               5              1            94   \n1                 1           5               3              2            93   \n2                 6          10               8              4           100   \n3                 8           9               9              8           100   \n4                 7           8               7              6           100   \n\n   Mean_Humidity  ...  Min_VisibilitykM  Max_Wind_SpeedKm_h  \\\n0             87  ...               4.0                  39   \n1             85  ...              10.0                  24   \n2             93  ...               2.0                  26   \n3             94  ...               2.0                  23   \n4             94  ...               3.0                  16   \n\n   Mean_Wind_SpeedKm_h  Max_Gust_SpeedKm_h  Precipitationmm  CloudCover  \\\n0                   26                58.0             5.08         6.0   \n1                   16                 NaN             0.00         6.0   \n2                   21                 NaN             1.02         7.0   \n3                   14                 NaN             0.25         7.0   \n4                   10                 NaN             0.00         7.0   \n\n   Events  WindDirDegrees           StateName  State  \n0    Rain             215  NordrheinWestfalen     NW  \n1    Rain             225  NordrheinWestfalen     NW  \n2    Rain             240  NordrheinWestfalen     NW  \n3    Rain             263  NordrheinWestfalen     NW  \n4    Rain             268  NordrheinWestfalen     NW  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>Date</th>\n      <th>Max_TemperatureC</th>\n      <th>Mean_TemperatureC</th>\n      <th>Min_TemperatureC</th>\n      <th>Dew_PointC</th>\n      <th>MeanDew_PointC</th>\n      <th>Min_DewpointC</th>\n      <th>Max_Humidity</th>\n      <th>Mean_Humidity</th>\n      <th>...</th>\n      <th>Min_VisibilitykM</th>\n      <th>Max_Wind_SpeedKm_h</th>\n      <th>Mean_Wind_SpeedKm_h</th>\n      <th>Max_Gust_SpeedKm_h</th>\n      <th>Precipitationmm</th>\n      <th>CloudCover</th>\n      <th>Events</th>\n      <th>WindDirDegrees</th>\n      <th>StateName</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-01</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1</td>\n      <td>94</td>\n      <td>87</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>39</td>\n      <td>26</td>\n      <td>58.0</td>\n      <td>5.08</td>\n      <td>6.0</td>\n      <td>Rain</td>\n      <td>215</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-02</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>93</td>\n      <td>85</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>24</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>6.0</td>\n      <td>Rain</td>\n      <td>225</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-03</td>\n      <td>11</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>8</td>\n      <td>4</td>\n      <td>100</td>\n      <td>93</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>26</td>\n      <td>21</td>\n      <td>NaN</td>\n      <td>1.02</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>240</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-04</td>\n      <td>9</td>\n      <td>9</td>\n      <td>8</td>\n      <td>9</td>\n      <td>9</td>\n      <td>8</td>\n      <td>100</td>\n      <td>94</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>23</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>0.25</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>263</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-05</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>8</td>\n      <td>7</td>\n      <td>6</td>\n      <td>100</td>\n      <td>94</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>16</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>268</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"4. Adding new columns to googletrends , and replace all instance of NI to HB,NI as it is usedelsewhere in all datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"googletrend['Date'] = googletrend.week.str.split(' - ', expand=True)[0]\ngoogletrend['State'] = googletrend.file.str.split('_', expand=True)[2]\n\ngoogletrend.loc[googletrend.State=='NI', \"State\"] = 'HB,NI'\n","execution_count":73,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Getting particular date fields from a complete datetime. We should always consider this stepwhen working with date time. this we will add to every table with a date field"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_datepart(df, fldname, drop=True, time=False):\n    fld = df[fldname]\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: \n        attr = attr + ['Hour', 'Minute', 'Second']\n    for n in attr:\n        df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n    if drop :\n        df.drop(fldname, axis=1, inplace=True)\n            ","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_datepart(weather, \"Date\", drop=False)\nadd_datepart(googletrend, \"Date\", drop=False)\nadd_datepart(train, \"Date\", drop=False)\nadd_datepart(test, \"Date\", drop=False)","execution_count":75,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. The Google trends data has a special category for the whole of germany - we'll pull that out to use explicitly"},{"metadata":{"trusted":true},"cell_type":"code","source":"trend_germany = googletrend[googletrend.file == \"Rossmann_DE\"]","execution_count":76,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"7. Now we will perform a outer join all datasets and then do a null check to see if the all records are consistent. "},{"metadata":{"trusted":true},"cell_type":"code","source":"store = join_df(store, store_states, \"Store\")\nlen(store[store.State.isnull()])\n\n# is isnull is zero it means the rows are consistent","execution_count":77,"outputs":[{"output_type":"execute_result","execution_count":77,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined  = join_df(train, store, \"Store\")\ncombined_test = join_df(test, store, \"Store\")\nlen(combined[combined.StoreType.isnull()]), len(combined_test[combined_test.StoreType.isnull()])","execution_count":78,"outputs":[{"output_type":"execute_result","execution_count":78,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined  = join_df(combined, googletrend, [\"State\", \"Year\", \"Week\"])\ncombined_test = join_df(combined, googletrend, [\"State\", \"Year\", \"Week\"])\nlen(combined[combined.trend.isnull()]), len(combined_test[combined_test.trend.isnull()])","execution_count":79,"outputs":[{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = combined.merge(trend_germany, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\ncombined_test = combined_test.merge(trend_germany, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\nlen(combined[combined.trend_DE.isnull()]),len(combined_test[combined_test.trend_DE.isnull()])","execution_count":80,"outputs":[{"output_type":"execute_result","execution_count":80,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = join_df(combined, weather, [\"State\",\"Date\"])\ncombined_test = join_df(combined_test, weather, [\"State\",\"Date\"])\nlen(combined[combined.Mean_TemperatureC.isnull()]),len(combined_test[combined_test.Mean_TemperatureC.isnull()])","execution_count":81,"outputs":[{"output_type":"execute_result","execution_count":81,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined, combined_test):\n    for c in df.columns:\n        if c.endswith('_y'):\n            if c in df.columns:\n                df.drop(c, inplace=True, axis=1)","execution_count":82,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"8. We will fill in the missing values to avoid complications with NA's. Na is when missing values invade a dataframe this is how pandas indicates missing values, many models have a problem "},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined, combined_test):\n    df['CompetitionOpenSinceYear'] = df.CompetitionOpenSinceYear.fillna(1900).astype(np.int32)\n    df['CompetitionOpenSinceMonth'] = df.CompetitionOpenSinceMonth.fillna(1).astype(np.int32)\n    df['Promo2SinceYear'] = df.Promo2SinceYear.fillna(1900).astype(np.int32)\n    df['Promo2SinceWeek'] = df.Promo2SinceWeek.fillna(1).astype(np.int32)","execution_count":83,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"9. Next we'll extract features \"CompetitionOpenSince\" and \"CompetitionDaysOpen\". "},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined,combined_test):\n    df[\"CompetitionOpenSince\"] = pd.to_datetime(dict(year=df.CompetitionOpenSinceYear, \n                                                     month=df.CompetitionOpenSinceMonth, day=15))\n    df[\"CompetitionDaysOpen\"] = df.Date.subtract(df.CompetitionOpenSince).dt.days","execution_count":84,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"10. Replacing some erroneous data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined, combined_test):\n    df.loc[df.CompetitionDaysOpen<0, \"CompetitionDaysOpen\"] = 0\n    df.loc[df.CompetitionOpenSinceYear<1990, \"CompetitionDaysOpen\"] = 0","execution_count":85,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"11. We add \"CompetitionMonthsOpen\" field, limiting the maximum to 2 years to limit number of unique categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined,combined_test):\n    df[\"CompetitionMonthsOpen\"] = df[\"CompetitionDaysOpen\"]//30\n    df.loc[df.CompetitionMonthsOpen>24, \"CompetitionMonthsOpen\"] = 24\ncombined.CompetitionMonthsOpen.unique()","execution_count":86,"outputs":[{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"array([24,  3, 19,  9,  0, 16, 17,  7, 15, 22, 11, 13,  2, 23, 12,  4, 10,  1, 14, 20,  8, 18,  6, 21,  5])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"12. Same we will do for promo dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install isoweek","execution_count":87,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: isoweek in /opt/conda/lib/python3.7/site-packages (1.3.3)\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from isoweek import Week\nfor df in (combined,combined_test):\n    df[\"Promo2Since\"] = pd.to_datetime(df.apply(lambda x: Week(\n        x.Promo2SinceYear, x.Promo2SinceWeek).monday(), axis=1))\n    df[\"Promo2Days\"] = df.Date.subtract(df[\"Promo2Since\"]).dt.days","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined,combined_test):\n    df.loc[df.Promo2Days<0, \"Promo2Days\"] = 0\n    df.loc[df.Promo2SinceYear<1990, \"Promo2Days\"] = 0\n    df[\"Promo2Weeks\"] = df[\"Promo2Days\"]//7\n    df.loc[df.Promo2Weeks<0, \"Promo2Weeks\"] = 0\n    df.loc[df.Promo2Weeks>25, \"Promo2Weeks\"] = 25\n    df.Promo2Weeks.unique()","execution_count":89,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"13. Converting to pickle for future"},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.to_pickle(PATH/'combined')\ncombined_test.to_pickle(PATH/'combined_test')","execution_count":90,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Durations\nIt is common when working with time series data to extract data that explains relationships across rows as opposed to columns, e.g.:\n\nRunning averages\nTime until next event\nTime since last event\n\nWe'll define a function `get_elapsed` for cumulative counting across a sorted dataframe. Given a particular field `fld` to monitor, this function will start tracking time since the last occurrence of that field. When the field is seen again, the counter is set to zero.\n\nUpon initialization, this will result in datetime na's until the field is encountered. This is reset every time a new store is seen. We'll see how to use this shortly."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_elapsed(fld, pre):\n    day1 = np.timedelta64(1, 'D')\n    last_date = np.datetime64()\n    last_store = 0\n    res = []\n\n    for s,v,d in zip(df.Store.values,df[fld].values, df.Date.values):\n        if s != last_store:\n            last_date = np.datetime64()\n            last_store = s\n        if v: last_date = d\n        res.append(((d-last_date).astype('timedelta64[D]') / day1))\n    df[pre+fld] = res","execution_count":91,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"14. applying to a subset of columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = [\"Date\", \"Store\", \"Promo\", \"StateHoliday\", \"SchoolHoliday\"]\ndf = train[columns].append(test[columns])","execution_count":92,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An example.\n\nSay we're looking at School Holiday. We'll first sort by Store, then Date, and then call add_elapsed('SchoolHoliday', 'After'): This will apply to each row with School Holiday:\n\nA applied to every row of the dataframe in order of store and date\n\nWill add to the dataframe the days since seeing a School Holiday\n\nIf we sort in the other direction, this will count the days until another holiday.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fld = 'SchoolHoliday'\ndf = df.sort_values(['Store', 'Date'])\nget_elapsed(fld, 'After')\ndf = df.sort_values(['Store', 'Date'], ascending=[True, False])\nget_elapsed(fld, 'Before')","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":94,"outputs":[{"output_type":"execute_result","execution_count":94,"data":{"text/plain":"           Date  Store  Promo  StateHoliday  SchoolHoliday  \\\n0    2015-09-17      1      1         False              0   \n856  2015-09-16      1      1         False              0   \n1712 2015-09-15      1      1         False              0   \n2568 2015-09-14      1      1         False              0   \n3424 2015-09-13      1      0         False              0   \n\n      AfterSchoolHoliday  BeforeSchoolHoliday  \n0                   13.0                  NaN  \n856                 12.0                  NaN  \n1712                11.0                  NaN  \n2568                10.0                  NaN  \n3424                 9.0                  NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-09-17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>2015-09-16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1712</th>\n      <td>2015-09-15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2568</th>\n      <td>2015-09-14</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3424</th>\n      <td>2015-09-13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for 2 more fiellds\n\nfld = 'StateHoliday'\ndf = df.sort_values(['Store', 'Date'])\nget_elapsed(fld, 'After')\ndf = df.sort_values(['Store', 'Date'], ascending=[True, False])\nget_elapsed(fld, 'Before')","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":96,"outputs":[{"output_type":"execute_result","execution_count":96,"data":{"text/plain":"           Date  Store  Promo  StateHoliday  SchoolHoliday  \\\n0    2015-09-17      1      1         False              0   \n856  2015-09-16      1      1         False              0   \n1712 2015-09-15      1      1         False              0   \n2568 2015-09-14      1      1         False              0   \n3424 2015-09-13      1      0         False              0   \n\n      AfterSchoolHoliday  BeforeSchoolHoliday  AfterStateHoliday  \\\n0                   13.0                  NaN              105.0   \n856                 12.0                  NaN              104.0   \n1712                11.0                  NaN              103.0   \n2568                10.0                  NaN              102.0   \n3424                 9.0                  NaN              101.0   \n\n      BeforeStateHoliday  \n0                    NaN  \n856                  NaN  \n1712                 NaN  \n2568                 NaN  \n3424                 NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n      <th>AfterStateHoliday</th>\n      <th>BeforeStateHoliday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-09-17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>105.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>2015-09-16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>104.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1712</th>\n      <td>2015-09-15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>103.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2568</th>\n      <td>2015-09-14</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>102.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3424</th>\n      <td>2015-09-13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>101.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fld = 'Promo'\ndf = df.sort_values(['Store', 'Date'])\nget_elapsed(fld, 'After')\ndf = df.sort_values(['Store', 'Date'], ascending=[True, False])\nget_elapsed(fld, 'Before')","execution_count":97,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":98,"outputs":[{"output_type":"execute_result","execution_count":98,"data":{"text/plain":"              Date  Store  Promo  StateHoliday  SchoolHoliday  \\\n1012749 2013-01-05   1115      0         False              1   \n1013864 2013-01-04   1115      0         False              1   \n1014979 2013-01-03   1115      0         False              1   \n1016094 2013-01-02   1115      0         False              1   \n1017208 2013-01-01   1115      0          True              1   \n\n         AfterSchoolHoliday  BeforeSchoolHoliday  AfterStateHoliday  \\\n1012749                 0.0                  0.0                4.0   \n1013864                 0.0                  0.0                3.0   \n1014979                 0.0                  0.0                2.0   \n1016094                 0.0                  0.0                1.0   \n1017208                 0.0                  0.0                0.0   \n\n         BeforeStateHoliday  AfterPromo  BeforePromo  \n1012749               -83.0         NaN         -2.0  \n1013864               -84.0         NaN         -3.0  \n1014979               -85.0         NaN         -4.0  \n1016094               -86.0         NaN         -5.0  \n1017208                 0.0         NaN         -6.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n      <th>AfterStateHoliday</th>\n      <th>BeforeStateHoliday</th>\n      <th>AfterPromo</th>\n      <th>BeforePromo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1012749</th>\n      <td>2013-01-05</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>-83.0</td>\n      <td>NaN</td>\n      <td>-2.0</td>\n    </tr>\n    <tr>\n      <th>1013864</th>\n      <td>2013-01-04</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>-84.0</td>\n      <td>NaN</td>\n      <td>-3.0</td>\n    </tr>\n    <tr>\n      <th>1014979</th>\n      <td>2013-01-03</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>-85.0</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n    </tr>\n    <tr>\n      <th>1016094</th>\n      <td>2013-01-02</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-86.0</td>\n      <td>NaN</td>\n      <td>-5.0</td>\n    </tr>\n    <tr>\n      <th>1017208</th>\n      <td>2013-01-01</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>-6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting active index to DAte\n\ndf = df.set_index(\"Date\")\n\n# setting null values from elapsed field to 0\ncolumns = ['SchoolHoliday', 'StateHoliday', 'Promo']\nfor o in ['Before', 'After']:\n    for p in columns:\n        a = o+p\n        df[a] = df[a].fillna(0).astype(int)\n","execution_count":99,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we'll demonstrate window functions in pandas to calculate rolling quantities.\n\nHere we're sorting by date (sort_index()) and counting the number of events of interest (sum()) defined in columns in the following week (rolling()), grouped by Store (groupby()). We do the same in the opposite direction."},{"metadata":{"trusted":true},"cell_type":"code","source":"bwd = df[['Store']+columns].sort_index().groupby(\"Store\").rolling(7, min_periods=1).sum()\nfwd = df[['Store']+columns].sort_index(ascending=False\n                                      ).groupby(\"Store\").rolling(7, min_periods=1).sum()\n","execution_count":100,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we want to drop the Store indices grouped together in the window function.\n\nOften in pandas, there is an option to do this in place. This is time and memory efficient when working with large datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"bwd.drop('Store',1,inplace=True)\nbwd.reset_index(inplace=True)\nfwd.drop('Store',1,inplace=True)\nfwd.reset_index(inplace=True)\ndf.reset_index(inplace=True)","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will merge these values into the dif\ndf = df.merge(bwd, 'left', ['Date', 'Store'], suffixes=['', '_bw'])\ndf = df.merge(fwd, 'left', ['Date', 'Store'], suffixes=['', '_fw'])\ndf.drop(columns,1,inplace=True)\ndf.head()\n","execution_count":102,"outputs":[{"output_type":"execute_result","execution_count":102,"data":{"text/plain":"        Date  Store  AfterSchoolHoliday  BeforeSchoolHoliday  \\\n0 2015-09-17      1                  13                    0   \n1 2015-09-16      1                  12                    0   \n2 2015-09-15      1                  11                    0   \n3 2015-09-14      1                  10                    0   \n4 2015-09-13      1                   9                    0   \n\n   AfterStateHoliday  BeforeStateHoliday  AfterPromo  BeforePromo  \\\n0                105                   0           0            0   \n1                104                   0           0            0   \n2                103                   0           0            0   \n3                102                   0           0            0   \n4                101                   0           9           -1   \n\n   SchoolHoliday_bw  StateHoliday_bw  Promo_bw  SchoolHoliday_fw  \\\n0               0.0              0.0       4.0               0.0   \n1               0.0              0.0       3.0               0.0   \n2               0.0              0.0       2.0               0.0   \n3               0.0              0.0       1.0               0.0   \n4               0.0              0.0       0.0               0.0   \n\n   StateHoliday_fw  Promo_fw  \n0              0.0       1.0  \n1              0.0       2.0  \n2              0.0       3.0  \n3              0.0       4.0  \n4              0.0       4.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n      <th>AfterStateHoliday</th>\n      <th>BeforeStateHoliday</th>\n      <th>AfterPromo</th>\n      <th>BeforePromo</th>\n      <th>SchoolHoliday_bw</th>\n      <th>StateHoliday_bw</th>\n      <th>Promo_bw</th>\n      <th>SchoolHoliday_fw</th>\n      <th>StateHoliday_fw</th>\n      <th>Promo_fw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-09-17</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>105</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-09-16</td>\n      <td>1</td>\n      <td>12</td>\n      <td>0</td>\n      <td>104</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-09-15</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0</td>\n      <td>103</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-09-14</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0</td>\n      <td>102</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-09-13</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>101</td>\n      <td>0</td>\n      <td>9</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It's usually a good idea to back up large tables of extracted / wrangled features before you join them onto another one, that way you can go back to it easily if you need to make changes to it.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_pickle(PATH/'df')\ndf[\"Date\"] = pd.to_datetime(df.Date)\ndf.columns","execution_count":103,"outputs":[{"output_type":"execute_result","execution_count":103,"data":{"text/plain":"Index(['Date', 'Store', 'AfterSchoolHoliday', 'BeforeSchoolHoliday',\n       'AfterStateHoliday', 'BeforeStateHoliday', 'AfterPromo', 'BeforePromo',\n       'SchoolHoliday_bw', 'StateHoliday_bw', 'Promo_bw', 'SchoolHoliday_fw',\n       'StateHoliday_fw', 'Promo_fw'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"joined = pd.read_pickle(PATH/'combined')\njoined_test = pd.read_pickle(PATH/f'combined_test')\njoined = join_df(joined, df, ['Store', 'Date'])\njoined_test = join_df(joined_test, df, ['Store', 'Date'])","execution_count":104,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The original authors also removed all instances where the store had zero sale / was closed. We speculate that this may have cost them a higher standing in the competition. One reason this may be the case is that a little exploratory data analysis reveals that there are often periods where stores are closed, typically for refurbishment. Before and after these periods, there are naturally spikes in sales that one might expect. By ommitting this data from their training, the authors gave up the ability to leverage information about these periods to predict this otherwise volatile behavior."},{"metadata":{"trusted":true},"cell_type":"code","source":"joined = joined[joined.Sales!=0]","execution_count":105,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Backing up this data as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"joined.reset_index(inplace=True)\njoined_test.reset_index(inplace=True)\njoined.to_pickle(PATH/'train_clean')\njoined_test.to_pickle(PATH/'test_clean')","execution_count":106,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}