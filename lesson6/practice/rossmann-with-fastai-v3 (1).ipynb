{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Fast ai v3 on Rosemann\n\nDone upto datacleaning."},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.basics import *","execution_count":3,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":4,"outputs":[{"output_type":"stream","text":"/kaggle/input/rossmann-store-sales/train.csv\n/kaggle/input/rossmann-store-sales/test.csv\n/kaggle/input/rossmann-store-sales/sample_submission.csv\n/kaggle/input/rossmann-store-sales/store.csv\n/kaggle/input/rossmann/state_names.csv\n/kaggle/input/rossmann/rossmann (1).tgz\n/kaggle/input/rossmann/googletrend.csv\n/kaggle/input/rossmann/weather.csv\n/kaggle/input/rossmann/train.csv\n/kaggle/input/rossmann/test.csv\n/kaggle/input/rossmann/sample_submission.csv\n/kaggle/input/rossmann/store.csv\n/kaggle/input/rossmann/store_states.csv\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Getting the data together\n\nThe extra data from rossmann one has to add to ones notebook.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = Config().data_path()/Path('rossmann/')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!mkdir {PATH}\n#mkdir: cannot create directory ‘/root/.fastai/data/rossmann’: No such file or directory\n!mkdir /root/.fastai/data/\n!mkdir /root/.fastai/data/rossmann","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp /kaggle/input/rossmann/*.csv {PATH}","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"table_names = ['train', 'store', 'store_states', 'state_names', 'googletrend', 'weather', 'test']","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tables = [pd.read_csv(PATH/f'{fname}.csv', low_memory=False) for fname in table_names]\ntrain, store, store_states, state_names, googletrend, weather, test = tables\ngoogletrend.tail()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"                file                     week  trend\n2067  Rossmann_DE_SL  2015-08-30 - 2015-09-05     95\n2068  Rossmann_DE_SL  2015-09-06 - 2015-09-12     47\n2069  Rossmann_DE_SL  2015-09-13 - 2015-09-19     80\n2070  Rossmann_DE_SL  2015-09-20 - 2015-09-26     57\n2071  Rossmann_DE_SL  2015-09-27 - 2015-10-03      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>week</th>\n      <th>trend</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2067</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-08-30 - 2015-09-05</td>\n      <td>95</td>\n    </tr>\n    <tr>\n      <th>2068</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-06 - 2015-09-12</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>2069</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-13 - 2015-09-19</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>2070</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-20 - 2015-09-26</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>2071</th>\n      <td>Rossmann_DE_SL</td>\n      <td>2015-09-27 - 2015-10-03</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"store.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n0      1         c          a               1270.0                        9.0   \n1      2         a          a                570.0                       11.0   \n2      3         a          a              14130.0                       12.0   \n3      4         c          c                620.0                        9.0   \n4      5         a          a              29910.0                        4.0   \n\n   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n0                    2008.0       0              NaN              NaN   \n1                    2007.0       1             13.0           2010.0   \n2                    2006.0       1             14.0           2011.0   \n3                    2009.0       0              NaN              NaN   \n4                    2015.0       0              NaN              NaN   \n\n     PromoInterval  \n0              NaN  \n1  Jan,Apr,Jul,Oct  \n2  Jan,Apr,Jul,Oct  \n3              NaN  \n4              NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>StoreType</th>\n      <th>Assortment</th>\n      <th>CompetitionDistance</th>\n      <th>CompetitionOpenSinceMonth</th>\n      <th>CompetitionOpenSinceYear</th>\n      <th>Promo2</th>\n      <th>Promo2SinceWeek</th>\n      <th>Promo2SinceYear</th>\n      <th>PromoInterval</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>c</td>\n      <td>a</td>\n      <td>1270.0</td>\n      <td>9.0</td>\n      <td>2008.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>a</td>\n      <td>a</td>\n      <td>570.0</td>\n      <td>11.0</td>\n      <td>2007.0</td>\n      <td>1</td>\n      <td>13.0</td>\n      <td>2010.0</td>\n      <td>Jan,Apr,Jul,Oct</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>a</td>\n      <td>a</td>\n      <td>14130.0</td>\n      <td>12.0</td>\n      <td>2006.0</td>\n      <td>1</td>\n      <td>14.0</td>\n      <td>2011.0</td>\n      <td>Jan,Apr,Jul,Oct</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>c</td>\n      <td>c</td>\n      <td>620.0</td>\n      <td>9.0</td>\n      <td>2009.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>a</td>\n      <td>a</td>\n      <td>29910.0</td>\n      <td>4.0</td>\n      <td>2015.0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_states.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"   Store State\n0      1    HE\n1      2    TH\n2      3    NW\n3      4    BE\n4      5    SN","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>HE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>TH</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>BE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>SN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather.tail()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"           file        Date  Max_TemperatureC  Mean_TemperatureC  \\\n15835  Saarland  2015-09-13                21                 17   \n15836  Saarland  2015-09-14                18                 14   \n15837  Saarland  2015-09-15                16                 12   \n15838  Saarland  2015-09-16                19                 15   \n15839  Saarland  2015-09-17                14                 13   \n\n       Min_TemperatureC  Dew_PointC  MeanDew_PointC  Min_DewpointC  \\\n15835                12          16              14             12   \n15836                11          15              12              7   \n15837                 9          11               8              7   \n15838                11          16              13             10   \n15839                12          14              12             10   \n\n       Max_Humidity  Mean_Humidity  ...  Max_VisibilityKm  Mean_VisibilityKm  \\\n15835           100             88  ...              31.0               15.0   \n15836            99             85  ...              31.0               13.0   \n15837            93             77  ...              31.0               12.0   \n15838            97             90  ...              31.0               10.0   \n15839            99             92  ...              31.0               14.0   \n\n       Min_VisibilitykM  Max_Wind_SpeedKm_h  Mean_Wind_SpeedKm_h  \\\n15835              10.0                  27                   10   \n15836               4.0                  32                   16   \n15837              10.0                  34                   14   \n15838               4.0                  32                   14   \n15839               8.0                  27                   16   \n\n       Max_Gust_SpeedKm_h  Precipitationmm  CloudCover             Events  \\\n15835                50.0             1.02         7.0               Rain   \n15836                53.0             9.91         5.0  Rain-Thunderstorm   \n15837                 NaN             0.00         5.0               Rain   \n15838                45.0            20.07         7.0  Rain-Thunderstorm   \n15839                47.0             6.10         6.0               Rain   \n\n       WindDirDegrees  \n15835             113  \n15836             213  \n15837             193  \n15838             147  \n15839             202  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>Date</th>\n      <th>Max_TemperatureC</th>\n      <th>Mean_TemperatureC</th>\n      <th>Min_TemperatureC</th>\n      <th>Dew_PointC</th>\n      <th>MeanDew_PointC</th>\n      <th>Min_DewpointC</th>\n      <th>Max_Humidity</th>\n      <th>Mean_Humidity</th>\n      <th>...</th>\n      <th>Max_VisibilityKm</th>\n      <th>Mean_VisibilityKm</th>\n      <th>Min_VisibilitykM</th>\n      <th>Max_Wind_SpeedKm_h</th>\n      <th>Mean_Wind_SpeedKm_h</th>\n      <th>Max_Gust_SpeedKm_h</th>\n      <th>Precipitationmm</th>\n      <th>CloudCover</th>\n      <th>Events</th>\n      <th>WindDirDegrees</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15835</th>\n      <td>Saarland</td>\n      <td>2015-09-13</td>\n      <td>21</td>\n      <td>17</td>\n      <td>12</td>\n      <td>16</td>\n      <td>14</td>\n      <td>12</td>\n      <td>100</td>\n      <td>88</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>15.0</td>\n      <td>10.0</td>\n      <td>27</td>\n      <td>10</td>\n      <td>50.0</td>\n      <td>1.02</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>113</td>\n    </tr>\n    <tr>\n      <th>15836</th>\n      <td>Saarland</td>\n      <td>2015-09-14</td>\n      <td>18</td>\n      <td>14</td>\n      <td>11</td>\n      <td>15</td>\n      <td>12</td>\n      <td>7</td>\n      <td>99</td>\n      <td>85</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>13.0</td>\n      <td>4.0</td>\n      <td>32</td>\n      <td>16</td>\n      <td>53.0</td>\n      <td>9.91</td>\n      <td>5.0</td>\n      <td>Rain-Thunderstorm</td>\n      <td>213</td>\n    </tr>\n    <tr>\n      <th>15837</th>\n      <td>Saarland</td>\n      <td>2015-09-15</td>\n      <td>16</td>\n      <td>12</td>\n      <td>9</td>\n      <td>11</td>\n      <td>8</td>\n      <td>7</td>\n      <td>93</td>\n      <td>77</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>12.0</td>\n      <td>10.0</td>\n      <td>34</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>5.0</td>\n      <td>Rain</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>15838</th>\n      <td>Saarland</td>\n      <td>2015-09-16</td>\n      <td>19</td>\n      <td>15</td>\n      <td>11</td>\n      <td>16</td>\n      <td>13</td>\n      <td>10</td>\n      <td>97</td>\n      <td>90</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>10.0</td>\n      <td>4.0</td>\n      <td>32</td>\n      <td>14</td>\n      <td>45.0</td>\n      <td>20.07</td>\n      <td>7.0</td>\n      <td>Rain-Thunderstorm</td>\n      <td>147</td>\n    </tr>\n    <tr>\n      <th>15839</th>\n      <td>Saarland</td>\n      <td>2015-09-17</td>\n      <td>14</td>\n      <td>13</td>\n      <td>12</td>\n      <td>14</td>\n      <td>12</td>\n      <td>10</td>\n      <td>99</td>\n      <td>92</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>14.0</td>\n      <td>8.0</td>\n      <td>27</td>\n      <td>16</td>\n      <td>47.0</td>\n      <td>6.10</td>\n      <td>6.0</td>\n      <td>Rain</td>\n      <td>202</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Data cleaning"},{"metadata":{},"cell_type":"markdown","source":"1. turning holidays into booleans to make the more convenient for modelling."},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.StateHoliday = train.StateHoliday != '0'\ntest.StateHoliday = test.StateHoliday != '0'","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. creating a custom join_df function for joining tables on specific fields"},{"metadata":{"trusted":true},"cell_type":"code","source":"def join_df(left, right, left_on, right_on=None, suffix='_y'):\n    if(right_on is None):\n        right_on = left_on\n    return left.merge(right, how='left', left_on=left_on, right_on=right_on, suffixes=(\"\", suffix))","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. joining weather and state_names"},{"metadata":{"trusted":true},"cell_type":"code","source":"weather = join_df(weather, state_names, \"file\", \"StateName\" )","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather.head()","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"                 file        Date  Max_TemperatureC  Mean_TemperatureC  \\\n0  NordrheinWestfalen  2013-01-01                 8                  4   \n1  NordrheinWestfalen  2013-01-02                 7                  4   \n2  NordrheinWestfalen  2013-01-03                11                  8   \n3  NordrheinWestfalen  2013-01-04                 9                  9   \n4  NordrheinWestfalen  2013-01-05                 8                  8   \n\n   Min_TemperatureC  Dew_PointC  MeanDew_PointC  Min_DewpointC  Max_Humidity  \\\n0                 2           7               5              1            94   \n1                 1           5               3              2            93   \n2                 6          10               8              4           100   \n3                 8           9               9              8           100   \n4                 7           8               7              6           100   \n\n   Mean_Humidity  ...  Min_VisibilitykM  Max_Wind_SpeedKm_h  \\\n0             87  ...               4.0                  39   \n1             85  ...              10.0                  24   \n2             93  ...               2.0                  26   \n3             94  ...               2.0                  23   \n4             94  ...               3.0                  16   \n\n   Mean_Wind_SpeedKm_h  Max_Gust_SpeedKm_h  Precipitationmm  CloudCover  \\\n0                   26                58.0             5.08         6.0   \n1                   16                 NaN             0.00         6.0   \n2                   21                 NaN             1.02         7.0   \n3                   14                 NaN             0.25         7.0   \n4                   10                 NaN             0.00         7.0   \n\n   Events  WindDirDegrees           StateName  State  \n0    Rain             215  NordrheinWestfalen     NW  \n1    Rain             225  NordrheinWestfalen     NW  \n2    Rain             240  NordrheinWestfalen     NW  \n3    Rain             263  NordrheinWestfalen     NW  \n4    Rain             268  NordrheinWestfalen     NW  \n\n[5 rows x 26 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file</th>\n      <th>Date</th>\n      <th>Max_TemperatureC</th>\n      <th>Mean_TemperatureC</th>\n      <th>Min_TemperatureC</th>\n      <th>Dew_PointC</th>\n      <th>MeanDew_PointC</th>\n      <th>Min_DewpointC</th>\n      <th>Max_Humidity</th>\n      <th>Mean_Humidity</th>\n      <th>...</th>\n      <th>Min_VisibilitykM</th>\n      <th>Max_Wind_SpeedKm_h</th>\n      <th>Mean_Wind_SpeedKm_h</th>\n      <th>Max_Gust_SpeedKm_h</th>\n      <th>Precipitationmm</th>\n      <th>CloudCover</th>\n      <th>Events</th>\n      <th>WindDirDegrees</th>\n      <th>StateName</th>\n      <th>State</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-01</td>\n      <td>8</td>\n      <td>4</td>\n      <td>2</td>\n      <td>7</td>\n      <td>5</td>\n      <td>1</td>\n      <td>94</td>\n      <td>87</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>39</td>\n      <td>26</td>\n      <td>58.0</td>\n      <td>5.08</td>\n      <td>6.0</td>\n      <td>Rain</td>\n      <td>215</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-02</td>\n      <td>7</td>\n      <td>4</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>2</td>\n      <td>93</td>\n      <td>85</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>24</td>\n      <td>16</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>6.0</td>\n      <td>Rain</td>\n      <td>225</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-03</td>\n      <td>11</td>\n      <td>8</td>\n      <td>6</td>\n      <td>10</td>\n      <td>8</td>\n      <td>4</td>\n      <td>100</td>\n      <td>93</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>26</td>\n      <td>21</td>\n      <td>NaN</td>\n      <td>1.02</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>240</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-04</td>\n      <td>9</td>\n      <td>9</td>\n      <td>8</td>\n      <td>9</td>\n      <td>9</td>\n      <td>8</td>\n      <td>100</td>\n      <td>94</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>23</td>\n      <td>14</td>\n      <td>NaN</td>\n      <td>0.25</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>263</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NordrheinWestfalen</td>\n      <td>2013-01-05</td>\n      <td>8</td>\n      <td>8</td>\n      <td>7</td>\n      <td>8</td>\n      <td>7</td>\n      <td>6</td>\n      <td>100</td>\n      <td>94</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>16</td>\n      <td>10</td>\n      <td>NaN</td>\n      <td>0.00</td>\n      <td>7.0</td>\n      <td>Rain</td>\n      <td>268</td>\n      <td>NordrheinWestfalen</td>\n      <td>NW</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 26 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"4. Adding new columns to googletrends , and replace all instance of NI to HB,NI as it is usedelsewhere in all datasets"},{"metadata":{"trusted":true},"cell_type":"code","source":"googletrend['Date'] = googletrend.week.str.split(' - ', expand=True)[0]\ngoogletrend['State'] = googletrend.file.str.split('_', expand=True)[2]\n\ngoogletrend.loc[googletrend.State=='NI', \"State\"] = 'HB,NI'\n","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"5. Getting particular date fields from a complete datetime. We should always consider this stepwhen working with date time. this we will add to every table with a date field"},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_datepart(df, fldname, drop=True, time=False):\n    fld = df[fldname]\n    fld_dtype = fld.dtype\n    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n        fld_dtype = np.datetime64\n    if not np.issubdtype(fld_dtype, np.datetime64):\n        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n    targ_pre = re.sub('[Dd]ate$', '', fldname)\n    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n    if time: \n        attr = attr + ['Hour', 'Minute', 'Second']\n    for n in attr:\n        df[targ_pre + n] = getattr(fld.dt, n.lower())\n    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n    if drop :\n        df.drop(fldname, axis=1, inplace=True)\n            ","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"add_datepart(weather, \"Date\", drop=False)\nadd_datepart(googletrend, \"Date\", drop=False)\nadd_datepart(train, \"Date\", drop=False)\nadd_datepart(test, \"Date\", drop=False)","execution_count":20,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"6. The Google trends data has a special category for the whole of germany - we'll pull that out to use explicitly"},{"metadata":{"trusted":true},"cell_type":"code","source":"trend_germany = googletrend[googletrend.file == \"Rossmann_DE\"]","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"7. Now we will perform a outer join all datasets and then do a null check to see if the all records are consistent. "},{"metadata":{"trusted":true},"cell_type":"code","source":"store = join_df(store, store_states, \"Store\")\nlen(store[store.State.isnull()])\n\n# is isnull is zero it means the rows are consistent","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"0"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined  = join_df(train, store, \"Store\")\ncombined_test = join_df(test, store, \"Store\")\nlen(combined[combined.StoreType.isnull()]), len(combined_test[combined_test.StoreType.isnull()])","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined  = join_df(combined, googletrend, [\"State\", \"Year\", \"Week\"])\ncombined_test = join_df(combined, googletrend, [\"State\", \"Year\", \"Week\"])\nlen(combined[combined.trend.isnull()]), len(combined_test[combined_test.trend.isnull()])","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = combined.merge(trend_germany, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\ncombined_test = combined_test.merge(trend_germany, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\nlen(combined[combined.trend_DE.isnull()]),len(combined_test[combined_test.trend_DE.isnull()])","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined = join_df(combined, weather, [\"State\",\"Date\"])\ncombined_test = join_df(combined_test, weather, [\"State\",\"Date\"])\nlen(combined[combined.Mean_TemperatureC.isnull()]),len(combined_test[combined_test.Mean_TemperatureC.isnull()])","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"(0, 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined, combined_test):\n    for c in df.columns:\n        if c.endswith('_y'):\n            if c in df.columns:\n                df.drop(c, inplace=True, axis=1)","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"8. We will fill in the missing values to avoid complications with NA's. Na is when missing values invade a dataframe this is how pandas indicates missing values, many models have a problem "},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined, combined_test):\n    df['CompetitionOpenSinceYear'] = df.CompetitionOpenSinceYear.fillna(1900).astype(np.int32)\n    df['CompetitionOpenSinceMonth'] = df.CompetitionOpenSinceMonth.fillna(1).astype(np.int32)\n    df['Promo2SinceYear'] = df.Promo2SinceYear.fillna(1900).astype(np.int32)\n    df['Promo2SinceWeek'] = df.Promo2SinceWeek.fillna(1).astype(np.int32)","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"9. Next we'll extract features \"CompetitionOpenSince\" and \"CompetitionDaysOpen\". "},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined,combined_test):\n    df[\"CompetitionOpenSince\"] = pd.to_datetime(dict(year=df.CompetitionOpenSinceYear, \n                                                     month=df.CompetitionOpenSinceMonth, day=15))\n    df[\"CompetitionDaysOpen\"] = df.Date.subtract(df.CompetitionOpenSince).dt.days","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"10. Replacing some erroneous data"},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined, combined_test):\n    df.loc[df.CompetitionDaysOpen<0, \"CompetitionDaysOpen\"] = 0\n    df.loc[df.CompetitionOpenSinceYear<1990, \"CompetitionDaysOpen\"] = 0","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"11. We add \"CompetitionMonthsOpen\" field, limiting the maximum to 2 years to limit number of unique categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined,combined_test):\n    df[\"CompetitionMonthsOpen\"] = df[\"CompetitionDaysOpen\"]//30\n    df.loc[df.CompetitionMonthsOpen>24, \"CompetitionMonthsOpen\"] = 24\ncombined.CompetitionMonthsOpen.unique()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"array([24,  3, 19,  9,  0, 16, 17,  7, 15, 22, 11, 13,  2, 23, 12,  4, 10,  1, 14, 20,  8, 18,  6, 21,  5])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"12. Same we will do for promo dates"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install isoweek","execution_count":32,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: isoweek in /opt/conda/lib/python3.7/site-packages (1.3.3)\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from isoweek import Week\nfor df in (combined,combined_test):\n    df[\"Promo2Since\"] = pd.to_datetime(df.apply(lambda x: Week(\n        x.Promo2SinceYear, x.Promo2SinceWeek).monday(), axis=1))\n    df[\"Promo2Days\"] = df.Date.subtract(df[\"Promo2Since\"]).dt.days","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (combined,combined_test):\n    df.loc[df.Promo2Days<0, \"Promo2Days\"] = 0\n    df.loc[df.Promo2SinceYear<1990, \"Promo2Days\"] = 0\n    df[\"Promo2Weeks\"] = df[\"Promo2Days\"]//7\n    df.loc[df.Promo2Weeks<0, \"Promo2Weeks\"] = 0\n    df.loc[df.Promo2Weeks>25, \"Promo2Weeks\"] = 25\n    df.Promo2Weeks.unique()","execution_count":34,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"13. Converting to pickle for future"},{"metadata":{"trusted":true},"cell_type":"code","source":"combined.to_pickle(PATH/'combined')\ncombined_test.to_pickle(PATH/'combined_test')","execution_count":35,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Durations\nIt is common when working with time series data to extract data that explains relationships across rows as opposed to columns, e.g.:\n\nRunning averages\nTime until next event\nTime since last event\n\nWe'll define a function `get_elapsed` for cumulative counting across a sorted dataframe. Given a particular field `fld` to monitor, this function will start tracking time since the last occurrence of that field. When the field is seen again, the counter is set to zero.\n\nUpon initialization, this will result in datetime na's until the field is encountered. This is reset every time a new store is seen. We'll see how to use this shortly."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_elapsed(fld, pre):\n    day1 = np.timedelta64(1, 'D')\n    last_date = np.datetime64()\n    last_store = 0\n    res = []\n\n    for s,v,d in zip(df.Store.values,df[fld].values, df.Date.values):\n        if s != last_store:\n            last_date = np.datetime64()\n            last_store = s\n        if v: last_date = d\n        res.append(((d-last_date).astype('timedelta64[D]') / day1))\n    df[pre+fld] = res","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"14. applying to a subset of columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"columns = [\"Date\", \"Store\", \"Promo\", \"StateHoliday\", \"SchoolHoliday\"]\ndf = train[columns].append(test[columns])","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An example.\n\nSay we're looking at School Holiday. We'll first sort by Store, then Date, and then call add_elapsed('SchoolHoliday', 'After'): This will apply to each row with School Holiday:\n\nA applied to every row of the dataframe in order of store and date\n\nWill add to the dataframe the days since seeing a School Holiday\n\nIf we sort in the other direction, this will count the days until another holiday.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"fld = 'SchoolHoliday'\ndf = df.sort_values(['Store', 'Date'])\nget_elapsed(fld, 'After')\ndf = df.sort_values(['Store', 'Date'], ascending=[True, False])\nget_elapsed(fld, 'Before')","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"           Date  Store  Promo  StateHoliday  SchoolHoliday  \\\n0    2015-09-17      1      1         False              0   \n856  2015-09-16      1      1         False              0   \n1712 2015-09-15      1      1         False              0   \n2568 2015-09-14      1      1         False              0   \n3424 2015-09-13      1      0         False              0   \n\n      AfterSchoolHoliday  BeforeSchoolHoliday  \n0                   13.0                  NaN  \n856                 12.0                  NaN  \n1712                11.0                  NaN  \n2568                10.0                  NaN  \n3424                 9.0                  NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-09-17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>2015-09-16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1712</th>\n      <td>2015-09-15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2568</th>\n      <td>2015-09-14</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3424</th>\n      <td>2015-09-13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for 2 more fiellds\n\nfld = 'StateHoliday'\ndf = df.sort_values(['Store', 'Date'])\nget_elapsed(fld, 'After')\ndf = df.sort_values(['Store', 'Date'], ascending=[True, False])\nget_elapsed(fld, 'Before')","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":41,"outputs":[{"output_type":"execute_result","execution_count":41,"data":{"text/plain":"           Date  Store  Promo  StateHoliday  SchoolHoliday  \\\n0    2015-09-17      1      1         False              0   \n856  2015-09-16      1      1         False              0   \n1712 2015-09-15      1      1         False              0   \n2568 2015-09-14      1      1         False              0   \n3424 2015-09-13      1      0         False              0   \n\n      AfterSchoolHoliday  BeforeSchoolHoliday  AfterStateHoliday  \\\n0                   13.0                  NaN              105.0   \n856                 12.0                  NaN              104.0   \n1712                11.0                  NaN              103.0   \n2568                10.0                  NaN              102.0   \n3424                 9.0                  NaN              101.0   \n\n      BeforeStateHoliday  \n0                    NaN  \n856                  NaN  \n1712                 NaN  \n2568                 NaN  \n3424                 NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n      <th>AfterStateHoliday</th>\n      <th>BeforeStateHoliday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-09-17</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>13.0</td>\n      <td>NaN</td>\n      <td>105.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>2015-09-16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n      <td>104.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1712</th>\n      <td>2015-09-15</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>NaN</td>\n      <td>103.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2568</th>\n      <td>2015-09-14</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>0</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>102.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3424</th>\n      <td>2015-09-13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>False</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>NaN</td>\n      <td>101.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fld = 'Promo'\ndf = df.sort_values(['Store', 'Date'])\nget_elapsed(fld, 'After')\ndf = df.sort_values(['Store', 'Date'], ascending=[True, False])\nget_elapsed(fld, 'Before')","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.tail()","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"              Date  Store  Promo  StateHoliday  SchoolHoliday  \\\n1012749 2013-01-05   1115      0         False              1   \n1013864 2013-01-04   1115      0         False              1   \n1014979 2013-01-03   1115      0         False              1   \n1016094 2013-01-02   1115      0         False              1   \n1017208 2013-01-01   1115      0          True              1   \n\n         AfterSchoolHoliday  BeforeSchoolHoliday  AfterStateHoliday  \\\n1012749                 0.0                  0.0                4.0   \n1013864                 0.0                  0.0                3.0   \n1014979                 0.0                  0.0                2.0   \n1016094                 0.0                  0.0                1.0   \n1017208                 0.0                  0.0                0.0   \n\n         BeforeStateHoliday  AfterPromo  BeforePromo  \n1012749               -83.0         NaN         -2.0  \n1013864               -84.0         NaN         -3.0  \n1014979               -85.0         NaN         -4.0  \n1016094               -86.0         NaN         -5.0  \n1017208                 0.0         NaN         -6.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>Promo</th>\n      <th>StateHoliday</th>\n      <th>SchoolHoliday</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n      <th>AfterStateHoliday</th>\n      <th>BeforeStateHoliday</th>\n      <th>AfterPromo</th>\n      <th>BeforePromo</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1012749</th>\n      <td>2013-01-05</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>-83.0</td>\n      <td>NaN</td>\n      <td>-2.0</td>\n    </tr>\n    <tr>\n      <th>1013864</th>\n      <td>2013-01-04</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>-84.0</td>\n      <td>NaN</td>\n      <td>-3.0</td>\n    </tr>\n    <tr>\n      <th>1014979</th>\n      <td>2013-01-03</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>-85.0</td>\n      <td>NaN</td>\n      <td>-4.0</td>\n    </tr>\n    <tr>\n      <th>1016094</th>\n      <td>2013-01-02</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-86.0</td>\n      <td>NaN</td>\n      <td>-5.0</td>\n    </tr>\n    <tr>\n      <th>1017208</th>\n      <td>2013-01-01</td>\n      <td>1115</td>\n      <td>0</td>\n      <td>True</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>-6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting active index to DAte\n\ndf = df.set_index(\"Date\")\n\n# setting null values from elapsed field to 0\ncolumns = ['SchoolHoliday', 'StateHoliday', 'Promo']\nfor o in ['Before', 'After']:\n    for p in columns:\n        a = o+p\n        df[a] = df[a].fillna(0).astype(int)\n","execution_count":44,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we'll demonstrate window functions in pandas to calculate rolling quantities.\n\nHere we're sorting by date (sort_index()) and counting the number of events of interest (sum()) defined in columns in the following week (rolling()), grouped by Store (groupby()). We do the same in the opposite direction."},{"metadata":{"trusted":true},"cell_type":"code","source":"bwd = df[['Store']+columns].sort_index().groupby(\"Store\").rolling(7, min_periods=1).sum()\nfwd = df[['Store']+columns].sort_index(ascending=False\n                                      ).groupby(\"Store\").rolling(7, min_periods=1).sum()\n","execution_count":45,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next we want to drop the Store indices grouped together in the window function.\n\nOften in pandas, there is an option to do this in place. This is time and memory efficient when working with large datasets."},{"metadata":{"trusted":true},"cell_type":"code","source":"bwd.drop('Store',1,inplace=True)\nbwd.reset_index(inplace=True)\nfwd.drop('Store',1,inplace=True)\nfwd.reset_index(inplace=True)\ndf.reset_index(inplace=True)","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we will merge these values into the dif\ndf = df.merge(bwd, 'left', ['Date', 'Store'], suffixes=['', '_bw'])\ndf = df.merge(fwd, 'left', ['Date', 'Store'], suffixes=['', '_fw'])\ndf.drop(columns,1,inplace=True)\ndf.head()\n","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"        Date  Store  AfterSchoolHoliday  BeforeSchoolHoliday  \\\n0 2015-09-17      1                  13                    0   \n1 2015-09-16      1                  12                    0   \n2 2015-09-15      1                  11                    0   \n3 2015-09-14      1                  10                    0   \n4 2015-09-13      1                   9                    0   \n\n   AfterStateHoliday  BeforeStateHoliday  AfterPromo  BeforePromo  \\\n0                105                   0           0            0   \n1                104                   0           0            0   \n2                103                   0           0            0   \n3                102                   0           0            0   \n4                101                   0           9           -1   \n\n   SchoolHoliday_bw  StateHoliday_bw  Promo_bw  SchoolHoliday_fw  \\\n0               0.0              0.0       4.0               0.0   \n1               0.0              0.0       3.0               0.0   \n2               0.0              0.0       2.0               0.0   \n3               0.0              0.0       1.0               0.0   \n4               0.0              0.0       0.0               0.0   \n\n   StateHoliday_fw  Promo_fw  \n0              0.0       1.0  \n1              0.0       2.0  \n2              0.0       3.0  \n3              0.0       4.0  \n4              0.0       4.0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Store</th>\n      <th>AfterSchoolHoliday</th>\n      <th>BeforeSchoolHoliday</th>\n      <th>AfterStateHoliday</th>\n      <th>BeforeStateHoliday</th>\n      <th>AfterPromo</th>\n      <th>BeforePromo</th>\n      <th>SchoolHoliday_bw</th>\n      <th>StateHoliday_bw</th>\n      <th>Promo_bw</th>\n      <th>SchoolHoliday_fw</th>\n      <th>StateHoliday_fw</th>\n      <th>Promo_fw</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2015-09-17</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>105</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2015-09-16</td>\n      <td>1</td>\n      <td>12</td>\n      <td>0</td>\n      <td>104</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2015-09-15</td>\n      <td>1</td>\n      <td>11</td>\n      <td>0</td>\n      <td>103</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2015-09-14</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0</td>\n      <td>102</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2015-09-13</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>101</td>\n      <td>0</td>\n      <td>9</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"It's usually a good idea to back up large tables of extracted / wrangled features before you join them onto another one, that way you can go back to it easily if you need to make changes to it.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_pickle(PATH/'df')\ndf[\"Date\"] = pd.to_datetime(df.Date)\ndf.columns","execution_count":48,"outputs":[{"output_type":"execute_result","execution_count":48,"data":{"text/plain":"Index(['Date', 'Store', 'AfterSchoolHoliday', 'BeforeSchoolHoliday',\n       'AfterStateHoliday', 'BeforeStateHoliday', 'AfterPromo', 'BeforePromo',\n       'SchoolHoliday_bw', 'StateHoliday_bw', 'Promo_bw', 'SchoolHoliday_fw',\n       'StateHoliday_fw', 'Promo_fw'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"joined = pd.read_pickle(PATH/'combined')\njoined_test = pd.read_pickle(PATH/f'combined_test')\njoined = join_df(joined, df, ['Store', 'Date'])\njoined_test = join_df(joined_test, df, ['Store', 'Date'])","execution_count":49,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The original authors also removed all instances where the store had zero sale / was closed. We speculate that this may have cost them a higher standing in the competition. One reason this may be the case is that a little exploratory data analysis reveals that there are often periods where stores are closed, typically for refurbishment. Before and after these periods, there are naturally spikes in sales that one might expect. By ommitting this data from their training, the authors gave up the ability to leverage information about these periods to predict this otherwise volatile behavior."},{"metadata":{"trusted":true},"cell_type":"code","source":"joined = joined[joined.Sales!=0]","execution_count":50,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Backing up this data as well"},{"metadata":{"trusted":true},"cell_type":"code","source":"joined.reset_index(inplace=True)\njoined_test.reset_index(inplace=True)\njoined.to_pickle(PATH/'train_clean')\njoined_test.to_pickle(PATH/'test_clean')","execution_count":51,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### lets look at final training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"#PATH\ntrain_df = pd.read_pickle(PATH/'train_clean')","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head().T","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"                                    0                    1  \\\nindex                               0                    1   \nStore                               1                    2   \nDayOfWeek                           5                    5   \nDate              2015-07-31 00:00:00  2015-07-31 00:00:00   \nSales                            5263                 6064   \n...                               ...                  ...   \nStateHoliday_bw                     0                    0   \nPromo_bw                            5                    5   \nSchoolHoliday_fw                    7                    1   \nStateHoliday_fw                     0                    0   \nPromo_fw                            5                    1   \n\n                                    2                    3  \\\nindex                               2                    3   \nStore                               3                    4   \nDayOfWeek                           5                    5   \nDate              2015-07-31 00:00:00  2015-07-31 00:00:00   \nSales                            8314                13995   \n...                               ...                  ...   \nStateHoliday_bw                     0                    0   \nPromo_bw                            5                    5   \nSchoolHoliday_fw                    5                    1   \nStateHoliday_fw                     0                    0   \nPromo_fw                            5                    1   \n\n                                    4  \nindex                               4  \nStore                               5  \nDayOfWeek                           5  \nDate              2015-07-31 00:00:00  \nSales                            4822  \n...                               ...  \nStateHoliday_bw                     0  \nPromo_bw                            5  \nSchoolHoliday_fw                    1  \nStateHoliday_fw                     0  \nPromo_fw                            1  \n\n[93 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>index</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>Store</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>DayOfWeek</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <td>2015-07-31 00:00:00</td>\n      <td>2015-07-31 00:00:00</td>\n      <td>2015-07-31 00:00:00</td>\n      <td>2015-07-31 00:00:00</td>\n      <td>2015-07-31 00:00:00</td>\n    </tr>\n    <tr>\n      <th>Sales</th>\n      <td>5263</td>\n      <td>6064</td>\n      <td>8314</td>\n      <td>13995</td>\n      <td>4822</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>StateHoliday_bw</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Promo_bw</th>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>SchoolHoliday_fw</th>\n      <td>7</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>StateHoliday_fw</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>Promo_fw</th>\n      <td>5</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>93 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = len(train_df)\nprint(n)","execution_count":56,"outputs":[{"output_type":"stream","text":"844338\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Experimenting with a sample"},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.tabular import *","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = np.random.permutation(range(n))[:2000]\nidx.sort()\nsmall_train_df = train_df.iloc[idx[:1000]]\nsmall_test_df = train_df.iloc[idx[1000:]]\nsmall_cont_vars = ['CompetitionDistance', 'Mean_Humidity']\nsmall_cat_vars = ['Store', 'DayOfWeek', 'PromoInterval']\nsmall_train_df = small_train_df[small_cat_vars + small_cont_vars + ['Sales']]\nsmall_test_df = small_test_df[small_cat_vars + small_cont_vars + ['Sales']]","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"small_train_df.head()","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"      Store  DayOfWeek    PromoInterval  CompetitionDistance  Mean_Humidity  \\\n26       27          5  Jan,Apr,Jul,Oct                 60.0             61   \n52       53          5              NaN              30360.0             61   \n151     152          5              NaN               1780.0             61   \n2137   1027          4  Jan,Apr,Jul,Oct                190.0             59   \n2331    106          3              NaN               1390.0             54   \n\n      Sales  \n26    13213  \n52     7540  \n151    6901  \n2137  17357  \n2331   9141  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>PromoInterval</th>\n      <th>CompetitionDistance</th>\n      <th>Mean_Humidity</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>5</td>\n      <td>Jan,Apr,Jul,Oct</td>\n      <td>60.0</td>\n      <td>61</td>\n      <td>13213</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>53</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>30360.0</td>\n      <td>61</td>\n      <td>7540</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>152</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>1780.0</td>\n      <td>61</td>\n      <td>6901</td>\n    </tr>\n    <tr>\n      <th>2137</th>\n      <td>1027</td>\n      <td>4</td>\n      <td>Jan,Apr,Jul,Oct</td>\n      <td>190.0</td>\n      <td>59</td>\n      <td>17357</td>\n    </tr>\n    <tr>\n      <th>2331</th>\n      <td>106</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>1390.0</td>\n      <td>54</td>\n      <td>9141</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"small_test_df.head()","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"        Store  DayOfWeek    PromoInterval  CompetitionDistance  Mean_Humidity  \\\n427711    216          2  Feb,May,Aug,Nov                190.0             69   \n428413    922          2              NaN               2110.0             69   \n428491   1000          2  Jan,Apr,Jul,Oct               2230.0             89   \n429166    564          1  Jan,Apr,Jul,Oct               6540.0             79   \n430168    425          6              NaN               1460.0             77   \n\n        Sales  \n427711   5540  \n428413   5757  \n428491   5900  \n429166   4853  \n430168   1857  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>PromoInterval</th>\n      <th>CompetitionDistance</th>\n      <th>Mean_Humidity</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>427711</th>\n      <td>216</td>\n      <td>2</td>\n      <td>Feb,May,Aug,Nov</td>\n      <td>190.0</td>\n      <td>69</td>\n      <td>5540</td>\n    </tr>\n    <tr>\n      <th>428413</th>\n      <td>922</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2110.0</td>\n      <td>69</td>\n      <td>5757</td>\n    </tr>\n    <tr>\n      <th>428491</th>\n      <td>1000</td>\n      <td>2</td>\n      <td>Jan,Apr,Jul,Oct</td>\n      <td>2230.0</td>\n      <td>89</td>\n      <td>5900</td>\n    </tr>\n    <tr>\n      <th>429166</th>\n      <td>564</td>\n      <td>1</td>\n      <td>Jan,Apr,Jul,Oct</td>\n      <td>6540.0</td>\n      <td>79</td>\n      <td>4853</td>\n    </tr>\n    <tr>\n      <th>430168</th>\n      <td>425</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>1460.0</td>\n      <td>77</td>\n      <td>1857</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorify = Categorify(small_cat_vars, small_cont_vars)\ncategorify(small_train_df)\ncategorify(small_test_df, test=True)","execution_count":65,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Categorify does basically the same thing that .classes thing for image recognition does for a dependent variable. It's going to take these strings, it's going to find all of the possible unique values of it, and it's going to create a list of them, and then it's going to turn the strings into numbers. So if I call it on my training set, that'll create categories there (small_train_df) and then I call it on my test set passing in test=true, that makes sure it's going to use the same categories that I had before. Now when I say .head, it looks exactly the same:"},{"metadata":{"trusted":true},"cell_type":"code","source":"small_test_df.head()","execution_count":66,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":"       Store DayOfWeek    PromoInterval  CompetitionDistance  Mean_Humidity  \\\n427711   216         2  Feb,May,Aug,Nov                190.0             69   \n428413   NaN         2              NaN               2110.0             69   \n428491   NaN         2  Jan,Apr,Jul,Oct               2230.0             89   \n429166   NaN         1  Jan,Apr,Jul,Oct               6540.0             79   \n430168   425         6              NaN               1460.0             77   \n\n        Sales  \n427711   5540  \n428413   5757  \n428491   5900  \n429166   4853  \n430168   1857  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>PromoInterval</th>\n      <th>CompetitionDistance</th>\n      <th>Mean_Humidity</th>\n      <th>Sales</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>427711</th>\n      <td>216</td>\n      <td>2</td>\n      <td>Feb,May,Aug,Nov</td>\n      <td>190.0</td>\n      <td>69</td>\n      <td>5540</td>\n    </tr>\n    <tr>\n      <th>428413</th>\n      <td>NaN</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2110.0</td>\n      <td>69</td>\n      <td>5757</td>\n    </tr>\n    <tr>\n      <th>428491</th>\n      <td>NaN</td>\n      <td>2</td>\n      <td>Jan,Apr,Jul,Oct</td>\n      <td>2230.0</td>\n      <td>89</td>\n      <td>5900</td>\n    </tr>\n    <tr>\n      <th>429166</th>\n      <td>NaN</td>\n      <td>1</td>\n      <td>Jan,Apr,Jul,Oct</td>\n      <td>6540.0</td>\n      <td>79</td>\n      <td>4853</td>\n    </tr>\n    <tr>\n      <th>430168</th>\n      <td>425</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>1460.0</td>\n      <td>77</td>\n      <td>1857</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"That's because Pandas has turned this into a categorical variable which internally is storing numbers but externally is showing me the strings. But I can look inside promo interval to look at the cat.categories, this is all standard Pandas here, to show me a list of all of what we would call \"classes\" in fast.ai or would be called just \"categories\" in Pandas."},{"metadata":{"trusted":true},"cell_type":"code","source":"small_train_df.PromoInterval.cat.categories","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"Index(['Feb,May,Aug,Nov', 'Jan,Apr,Jul,Oct', 'Mar,Jun,Sept,Dec'], dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"small_train_df['PromoInterval'].cat.codes[:5]","execution_count":68,"outputs":[{"output_type":"execute_result","execution_count":68,"data":{"text/plain":"26      1\n52     -1\n151    -1\n2137    1\n2331   -1\ndtype: int8"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"So then if I look at the cat.codes, you can see here this list here is the numbers that are actually stored (-1, -1, 1, -1, 1). What are these minus ones? The minus ones represent NaN - they represent \"missing\". So Pandas uses the special code -1 to be mean missing.\n\nAs you know, these are going to end up in an embedding matrix, and we can't look up item -1 in an embedding matrix. So internally in fast.ai, we add one to all of these."},{"metadata":{"trusted":true},"cell_type":"code","source":"fill_missing = FillMissing(small_cat_vars,small_cont_vars)\nfill_missing(small_train_df)\nfill_missing(small_test_df, test=True)","execution_count":70,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Another useful preprocessor is FillMissing. Again, you can call it on the data frame, you can call on the test passing in test=true."},{"metadata":{"trusted":true},"cell_type":"code","source":"small_train_df[small_train_df['CompetitionDistance_na'] == True]\n","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"       Store DayOfWeek PromoInterval  CompetitionDistance  Mean_Humidity  \\\n199377   622         6           NaN               2470.0             81   \n317920   622         2           NaN               2470.0             65   \n334447   291         2           NaN               2470.0             86   \n\n        Sales  CompetitionDistance_na  \n199377   3548                    True  \n317920   4835                    True  \n334447   6020                    True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Store</th>\n      <th>DayOfWeek</th>\n      <th>PromoInterval</th>\n      <th>CompetitionDistance</th>\n      <th>Mean_Humidity</th>\n      <th>Sales</th>\n      <th>CompetitionDistance_na</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>199377</th>\n      <td>622</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>2470.0</td>\n      <td>81</td>\n      <td>3548</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>317920</th>\n      <td>622</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2470.0</td>\n      <td>65</td>\n      <td>4835</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>334447</th>\n      <td>291</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>2470.0</td>\n      <td>86</td>\n      <td>6020</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"This will create, for anything that has a missing value, it'll create an additional column with the column name underscore na (e.g. CompetitionDistance_na) and it will set it for true for any time that was missing. Then what we do is, we replace competition distance with the median for those. Why do we do this? Well, because very commonly the fact that something's missing is of itself interesting (i.e. it turns out the fact that this is missing helps you predict your outcome). So we certainly want to keep that information in a convenient boolean column, so that our deep learning model can use it to predict things.\n\nBut then, we need competition distance to be a continuous variable so we can use it in the continuous variable part of our model. So we can replace it with almost any number because if it turns out that the missingness is important, it can use the interaction of CompetitionDistance_na and CompetitionDistance to make predictions. So that's what FillMissing does."},{"metadata":{},"cell_type":"markdown","source":"# Preparing full dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_pickle(PATH/'train_clean')\ntest_df = pd.read_pickle(PATH/'test_clean')","execution_count":90,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df), len(test_df)","execution_count":91,"outputs":[{"output_type":"execute_result","execution_count":91,"data":{"text/plain":"(844338, 1017209)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The main thing you have to do if you want to create a data bunch of tabular data is tell it what are your categorical variables and what are your continuous variables. As we discussed last week briefly, your categorical variables are not just strings and things, but also I include things like day of week and month and day of month. Even though they're numbers, I make them categorical variables. Because, for example, day of month, I don't think it's going to have a nice smooth curve. I think that the fifteenth of the month and the first of the month and the 30th of the month are probably going to have different purchasing behavior to other days of the month. Therefore, if I make it a categorical variable, it's going to end up creating an embedding matrix and those different days of the month can get different behaviors.\n\nYou've actually got to think carefully about which things should be categorical variables. On the whole, if in doubt and there are not too many levels in your category (that's called the cardinality), if your cardinality is not too high, I would put it as a categorical variable. You can always try an each and see which works best."},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n    'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n    'SchoolHoliday_fw', 'SchoolHoliday_bw']\n\ncont_vars = ['CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n   'AfterStateHoliday', 'BeforeStateHoliday', 'Promo', 'SchoolHoliday']","execution_count":75,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You don't have to manually call preprocesses yourself. When you call any kind of item list creator, you can pass in a list of pre processes which you can create like this:"},{"metadata":{"trusted":true},"cell_type":"code","source":"procs = [FillMissing, Categorify, Normalize]","execution_count":74,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Find validation set indexes\n\nOur final data frame that we're going to pass in is going to be a training set with the categorical variables, the continuous variables, the dependent variable, and the date. The date, we're just going to use to create a validation set where we are basically going to say the validation set is going to be the same number of records at the end of the time period that the test set is for Kaggle. That way, we should be able to validate our model nicely."},{"metadata":{"trusted":true},"cell_type":"code","source":"dep_var = 'Sales'\ndf = train_df[cat_vars + cont_vars + [dep_var,'Date']].copy()\ntest_df['Date'].min(), test_df['Date'].max()","execution_count":84,"outputs":[{"output_type":"execute_result","execution_count":84,"data":{"text/plain":"(Timestamp('2013-01-01 00:00:00'), Timestamp('2015-07-31 00:00:00'))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cut = train_df['Date'][(train_df['Date'] == train_df['Date'][len(test_df)])].index.max()\n#print(train_df['Date'][len(test_df)])\nprint(len(train_df))\nlen(test_df)\n\n\n# getting index value error so skipping cut and its demonstration","execution_count":89,"outputs":[{"output_type":"stream","text":"844338\n","name":"stdout"},{"output_type":"execute_result","execution_count":89,"data":{"text/plain":"1017209"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"length of train_df should be more than test_df\nTheres a big here somewhere in this notebook and I intend to find it."},{"metadata":{},"cell_type":"markdown","source":"# getting data from fastai"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (TabularList.from_df(df, path=PATH, cat_names=cat_vars, cont_names=cont_vars, procs=procs,)\n                .split_by_idx(valid_idx)\n                .label_from_df(cols=dep_var, label_cls=FloatList, log=True)\n                .add_test(TabularList.from_df(test_df, path=PATH, cat_names=cat_vars, cont_names=cont_vars))\n                .databunch())","execution_count":83,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'valid_idx' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-83-c2312fea6500>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m data = (TabularList.from_df(df, path=PATH, cat_names=cat_vars, cont_names=cont_vars, procs=procs,)\n\u001b[0;32m----> 2\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0msplit_by_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mlabel_from_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdep_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFloatList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0madd_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTabularList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcont_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 .databunch())\n","\u001b[0;31mNameError\u001b[0m: name 'valid_idx' is not defined"]}]},{"metadata":{},"cell_type":"markdown","source":"This is saying \"ok, I want to fill missing, I want to categorify, I want to normalize (i.e. for continuous variables, it'll subtract the mean and divide by the standard deviation to help a train more easily).\" So you just say, those are my procs and then you can just pass it in there and that's it.\n\nLater on, you can go data.export and it'll save all the metadata for that data bunch so you can, later on, load it in knowing exactly what your category codes are, exactly what median values used for replacing the missing values, and exactly what means and standard deviations you normalize by."},{"metadata":{},"cell_type":"markdown","source":"### Creating model"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_log_y = np.log(np.max(train_df['Sales']) * 1.2)\ny_range = torch.tensor([0, max_log_y],\n                      device = defaults.device)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = tabular_learner(data, layers= [1000,500], ps=[0.001,0.01], emb_drop=0.04, y_range=y_range, metrics =exp_rmspe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data.train_ds.cont_names)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 1e-3, wd=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses(skip_start=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 3e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(5, 3e-4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submit"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_preds = learn.get_preds(DatasetType.Test)\ntest_df[\"Sales\"] = np.exp(test_preds[0].data).numpy().T[0]\ntest_df[[\"Id\", \"Sales\"]] = test_df[[\"Id\", \"Sales\"]].astype(\"int\")\ntest_df[[\"Id\", \"Sales\"]].to_csv(\"rossmann_submission.csv\", index=False)","execution_count":92,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'learn' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-058b1ad7520e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sales\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}