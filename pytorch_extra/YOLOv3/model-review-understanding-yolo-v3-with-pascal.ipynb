{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "entertaining-mississippi",
   "metadata": {
    "papermill": {
     "duration": 0.007917,
     "end_time": "2021-05-18T12:04:33.085633",
     "exception": false,
     "start_time": "2021-05-18T12:04:33.077716",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# YOLO Algorithm\n",
    "\n",
    "![](https://pyimagesearch.com/wp-content/uploads/2018/11/yolo_design.jpg)\n",
    "\n",
    "\n",
    "You live only once algorithm. You can find the paper here: https://arxiv.org/pdf/1506.02640.pdf\n",
    "\n",
    "In yolo you, \"separated bounding boxes and\n",
    "associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from\n",
    "full images in one evaluation. Since the whole detection\n",
    "pipeline is a single network, it can be optimized end-to-end\n",
    "directly on detection performance.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-speed",
   "metadata": {
    "papermill": {
     "duration": 0.00609,
     "end_time": "2021-05-18T12:04:33.098239",
     "exception": false,
     "start_time": "2021-05-18T12:04:33.092149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Yolo devides image into a S X S grid.\n",
    "\n",
    "Then each grid cell predicts bounding boxes and confidence scores for those boxes. \n",
    "\n",
    "These confidence scores reflect how\n",
    "confident the model is that the box contains an object and\n",
    "also how accurate it thinks the box is that it predicts. Formally we define confidence as Pr(Object) âˆ— IOUtruth\n",
    "pred . \n",
    "\n",
    "If no\n",
    "object exists in that cell, the confidence scores should be\n",
    "zero. Otherwise we want the confidence score to equal the\n",
    "intersection over union (IOU) between the predicted box\n",
    "and the ground truth.\n",
    "\n",
    "Each bounding box consists of 5 predictions: x, y, w, h,\n",
    "and confidence. The (x, y) coordinates represent the center\n",
    "of the box relative to the bounds of the grid cell. The width\n",
    "and height are predicted relative to the whole image. \n",
    "\n",
    "Finally\n",
    "the confidence prediction represents the IOU between the\n",
    "predicted box and any ground truth box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-location",
   "metadata": {
    "papermill": {
     "duration": 0.006459,
     "end_time": "2021-05-18T12:04:33.111104",
     "exception": false,
     "start_time": "2021-05-18T12:04:33.104645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# YOLO Architecture\n",
    "\n",
    "![](https://www.inverseai.com/media/blog_uploads/2020/12/08/yolo_model_ds2WXzl.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-philip",
   "metadata": {
    "papermill": {
     "duration": 0.006002,
     "end_time": "2021-05-18T12:04:33.123479",
     "exception": false,
     "start_time": "2021-05-18T12:04:33.117477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The main difference in yolo v3 is that they have adapted different scales so that it is not just a 7 by 7 grid. 13 X 13, 26 x 26, 52 x 52.\n",
    "\n",
    "It also has anchor boxes which we can use anchor box to adjust the images, this they used through k means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-reach",
   "metadata": {
    "papermill": {
     "duration": 0.005945,
     "end_time": "2021-05-18T12:04:33.135747",
     "exception": false,
     "start_time": "2021-05-18T12:04:33.129802",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "academic-pasta",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T12:04:33.152741Z",
     "iopub.status.busy": "2021-05-18T12:04:33.151732Z",
     "iopub.status.idle": "2021-05-18T12:04:34.135433Z",
     "shell.execute_reply": "2021-05-18T12:04:34.134788Z"
    },
    "papermill": {
     "duration": 0.993604,
     "end_time": "2021-05-18T12:04:34.135604",
     "exception": false,
     "start_time": "2021-05-18T12:04:33.142000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "trained-breathing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T12:04:34.156049Z",
     "iopub.status.busy": "2021-05-18T12:04:34.155447Z",
     "iopub.status.idle": "2021-05-18T12:04:34.157138Z",
     "shell.execute_reply": "2021-05-18T12:04:34.157602Z"
    },
    "papermill": {
     "duration": 0.015377,
     "end_time": "2021-05-18T12:04:34.157774",
     "exception": false,
     "start_time": "2021-05-18T12:04:34.142397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Information about architecture config:\n",
    "Tuple is structured by (filters, kernel_size, stride) \n",
    "Every conv is a same convolution. \n",
    "List is structured by \"B\" indicating a residual block followed by the number of repeats\n",
    "\"S\" is for scale prediction block and computing the yolo loss\n",
    "\"U\" is for upsampling the feature map and concatenating with a previous layer\n",
    "\"\"\"\n",
    "config = [\n",
    "    (32, 3, 1),\n",
    "    (64, 3, 2),\n",
    "    [\"B\", 1],\n",
    "    (128, 3, 2),\n",
    "    [\"B\", 2],\n",
    "    (256, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (512, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (1024, 3, 2),\n",
    "    [\"B\", 4],  # To this point is Darknet-53\n",
    "    (512, 1, 1),\n",
    "    (1024, 3, 1),\n",
    "    \"S\", # scale 1\n",
    "    (256, 1, 1),\n",
    "    \"U\", # upsample\n",
    "    (256, 1, 1),\n",
    "    (512, 3, 1),\n",
    "    \"S\",\n",
    "    (128, 1, 1),\n",
    "    \"U\",\n",
    "    (128, 1, 1),\n",
    "    (256, 3, 1),\n",
    "    \"S\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "three-dispute",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T12:04:34.177969Z",
     "iopub.status.busy": "2021-05-18T12:04:34.177081Z",
     "iopub.status.idle": "2021-05-18T12:04:34.180003Z",
     "shell.execute_reply": "2021-05-18T12:04:34.179571Z"
    },
    "papermill": {
     "duration": 0.015584,
     "end_time": "2021-05-18T12:04:34.180138",
     "exception": false,
     "start_time": "2021-05-18T12:04:34.164554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.1)\n",
    "        self.use_bn_act = bn_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn_act:\n",
    "            return self.leaky(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "foreign-cleaners",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T12:04:34.200056Z",
     "iopub.status.busy": "2021-05-18T12:04:34.199250Z",
     "iopub.status.idle": "2021-05-18T12:04:34.201439Z",
     "shell.execute_reply": "2021-05-18T12:04:34.201918Z"
    },
    "papermill": {
     "duration": 0.015381,
     "end_time": "2021-05-18T12:04:34.202077",
     "exception": false,
     "start_time": "2021-05-18T12:04:34.186696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, use_residual=True, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for repeat in range(num_repeats):\n",
    "            self.layers += [\n",
    "                nn.Sequential(\n",
    "                    CNNBlock(channels, channels // 2, kernel_size=1),\n",
    "                    CNNBlock(channels // 2, channels, kernel_size=3, padding=1),\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        self.use_residual = use_residual\n",
    "        self.num_repeats = num_repeats\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            if self.use_residual:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "informal-cause",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T12:04:34.221935Z",
     "iopub.status.busy": "2021-05-18T12:04:34.221221Z",
     "iopub.status.idle": "2021-05-18T12:04:34.224349Z",
     "shell.execute_reply": "2021-05-18T12:04:34.223844Z"
    },
    "papermill": {
     "duration": 0.015796,
     "end_time": "2021-05-18T12:04:34.224477",
     "exception": false,
     "start_time": "2021-05-18T12:04:34.208681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScalePrediction(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.pred = nn.Sequential(\n",
    "            CNNBlock(in_channels, 2 * in_channels, kernel_size=3, padding=1),\n",
    "            CNNBlock(\n",
    "                2 * in_channels, (num_classes + 5) * 3, bn_act=False, kernel_size=1\n",
    "            ),\n",
    "        )\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (\n",
    "            self.pred(x)\n",
    "            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])\n",
    "            .permute(0, 1, 3, 4, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bright-gospel",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T12:04:34.250287Z",
     "iopub.status.busy": "2021-05-18T12:04:34.249657Z",
     "iopub.status.idle": "2021-05-18T12:04:34.252648Z",
     "shell.execute_reply": "2021-05-18T12:04:34.252070Z"
    },
    "papermill": {
     "duration": 0.02118,
     "end_time": "2021-05-18T12:04:34.252782",
     "exception": false,
     "start_time": "2021-05-18T12:04:34.231602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YOLOv3(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=20):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.layers = self._create_conv_layers()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        route_connections = []\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, ScalePrediction):\n",
    "                outputs.append(layer(x))\n",
    "                continue\n",
    "            x = layer(x)\n",
    "            \n",
    "            if isinstance(layer, ResidualBlock) and layer.num_repeats == 8:\n",
    "                route_connections.append(x)\n",
    "            elif isinstance(layer, nn.Upsample):\n",
    "                x = torch.cat([x, route_connections[-1]], dim = 1)\n",
    "                route_connections.pop()\n",
    "        return outputs\n",
    "    \n",
    "    def _create_conv_layers(self):\n",
    "        layers = nn.ModuleList()\n",
    "        in_channels = self.in_channels\n",
    "        \n",
    "        for module in config:\n",
    "            if isinstance(module, tuple):\n",
    "                out_channels, kernel_size, stride = module\n",
    "                layers.append(CNNBlock(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=1 if kernel_size == 3 else 0,\n",
    "                    \n",
    "                ))\n",
    "                \n",
    "                in_channels = out_channels\n",
    "        \n",
    "            elif isinstance(module, list):\n",
    "                num_repeats= module[1]\n",
    "                layers.append(ResidualBlock(in_channels, num_repeats=num_repeats))\n",
    "            \n",
    "            elif isinstance(module, str):\n",
    "                if module == \"S\":\n",
    "                    layers += [\n",
    "                        ResidualBlock(in_channels, use_residual=False, num_repeats=1),\n",
    "                        CNNBlock(in_channels, in_channels//2, kernel_size=1),\n",
    "                        ScalePrediction(in_channels//2, num_classes=self.num_classes)\n",
    "        \n",
    "                    ]\n",
    "                    \n",
    "                    in_channels = in_channels //2\n",
    "                elif module == \"U\":\n",
    "                    layers.append(nn.Upsample(scale_factor=2))\n",
    "                    in_channels =in_channels * 3\n",
    "        return layers\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedicated-brighton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-18T12:04:34.273915Z",
     "iopub.status.busy": "2021-05-18T12:04:34.273121Z",
     "iopub.status.idle": "2021-05-18T12:04:41.532636Z",
     "shell.execute_reply": "2021-05-18T12:04:41.532054Z"
    },
    "papermill": {
     "duration": 7.272853,
     "end_time": "2021-05-18T12:04:41.532771",
     "exception": false,
     "start_time": "2021-05-18T12:04:34.259918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It ran without a hitch!\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_classes = 20\n",
    "    IMAGE_SIZE = 416\n",
    "    model = YOLOv3(num_classes=num_classes)\n",
    "    x = torch.randn((2,3,IMAGE_SIZE, IMAGE_SIZE))\n",
    "    out = model(x)\n",
    "    \n",
    "    assert model(x)[0].shape == (2,3,IMAGE_SIZE//32, IMAGE_SIZE//32, num_classes + 5)\n",
    "    assert model(x)[1].shape == (2,3,IMAGE_SIZE//16, IMAGE_SIZE//16, num_classes + 5)\n",
    "    assert model(x)[2].shape == (2,3,IMAGE_SIZE//8, IMAGE_SIZE//8, num_classes + 5)\n",
    "    print(\"It ran without a hitch!\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.539507,
   "end_time": "2021-05-18T12:04:42.350159",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-18T12:04:25.810652",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
