{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Learning Pytorch\nThis series would be taken from various tutorial available in youtube.\n\n## 1 : Creating a simple convolutional neural network\nThis one is taken from excellent channel Alladin Perrson : https://www.youtube.com/watch?v=Jy4wM2X21u0&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=3\n\n![](https://i.morioh.com/200620/5b0ea047.jpg)","metadata":{}},{"cell_type":"markdown","source":"## Handling imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"markdown","source":"## creating the model","metadata":{}},{"cell_type":"code","source":"class SimpleNN(nn.Module):\n    def __init__(self, model_size, num_of_classes):\n        super(SimpleNN, self).__init__()\n        self.fc1 = nn.Linear(model_size, 48)\n        self.fc2 = nn.Linear(48, num_of_classes)\n    \n    def forward(self, x):\n        out = self.fc1(x)\n        out = F.relu(out)\n        out = self.fc2(out)\n        return out","metadata":{"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"class SimpleCNN(nn.Module):\n    def __init__(self, in_channels=1, classes=10):\n        super(SimpleCNN, self).__init__()\n        \n        self.conv1 = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=8, \n            padding=(1,1), \n            kernel_size=(3,3), \n            stride=(1,1)) # same convolution, input will be same as output\n        \n        self.conv2 = nn.Conv2d(\n            in_channels=8, \n            out_channels=16, \n            padding=(1,1), \n            kernel_size=(3,3), \n            stride=(1,1))\n        \n        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n        self.fc1 = nn.Linear(16*7*7, classes)\n    \n    def forward(self, x):\n        out = F.relu(self.conv1(x))\n        out = self.pool(out)\n        out = F.relu(self.conv2(out))\n        out = self.pool(out)\n        out = out.reshape(out.shape[0], -1)\n        out = self.fc1(out)\n        return out\n        \n        ","metadata":{"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(self, in_channels=1, num_classes=10):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=8,\n            kernel_size=(3, 3),\n            stride=(1, 1),\n            padding=(1, 1),\n        )\n        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n        self.conv2 = nn.Conv2d(\n            in_channels=8,\n            out_channels=16,\n            kernel_size=(3, 3),\n            stride=(1, 1),\n            padding=(1, 1),\n        )\n        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = x.reshape(x.shape[0], -1)\n        x = self.fc1(x)\n        return x","metadata":{"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"## Getting device information","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"## Putting in the hyper parameters","metadata":{}},{"cell_type":"code","source":"num_epochs = 5\nlearning_rate = 0.001\nbatch_size=64\n# input_size=784\nin_channels=1\nnum_of_classes=10\n","metadata":{"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"markdown","source":"## Getting the dataset","metadata":{}},{"cell_type":"code","source":"# try:\n#     train_dataset = datasets.MNIST(root='./dataset/', download=True, train=True, transform=transforms.ToTensor())\n#     test_dataset = datasets.MNIST(root='./dataset/', download=True, train=False, transform=transforms.ToTensor())\n#     train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n#     test_dataloader = DataLoader(dataset = test_dataset, batch_size=batch_size, shuffle=True)\n# except Exception as e:\n#     print(e)\n    ","metadata":{"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"since getting a from interenet isn't reliable lets try with a dataset from csv\n\n## Custom data set class\n\nwith help from https://www.youtube.com/watch?v=PXOzkkB5eH0","metadata":{}},{"cell_type":"code","source":"import numpy as np","metadata":{"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"markdown","source":"testing","metadata":{}},{"cell_type":"code","source":"xy = np.loadtxt('../input/mnist-in-csv/mnist_train.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\nx = xy[:,1:]\ny = xy[:,[0]]\nprint(x, y)\n    ","metadata":{"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]] [[5.]\n [0.]\n [4.]\n ...\n [5.]\n [6.]\n [8.]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndd = pd.read_csv('../input/mnist-in-csv/mnist_train.csv', dtype=np.float)\ndd.head()","metadata":{"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n0    5.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n1    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n2    4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n3    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n4    9.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n\n   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n3    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n4    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>1x1</th>\n      <th>1x2</th>\n      <th>1x3</th>\n      <th>1x4</th>\n      <th>1x5</th>\n      <th>1x6</th>\n      <th>1x7</th>\n      <th>1x8</th>\n      <th>1x9</th>\n      <th>...</th>\n      <th>28x19</th>\n      <th>28x20</th>\n      <th>28x21</th>\n      <th>28x22</th>\n      <th>28x23</th>\n      <th>28x24</th>\n      <th>28x25</th>\n      <th>28x26</th>\n      <th>28x27</th>\n      <th>28x28</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_dash = torch.from_numpy(dd.iloc[:,0].values) # y\ny_dash","metadata":{"trusted":true},"execution_count":127,"outputs":[{"execution_count":127,"output_type":"execute_result","data":{"text/plain":"tensor([5., 0., 4.,  ..., 5., 6., 8.], dtype=torch.float64)"},"metadata":{}}]},{"cell_type":"code","source":"type(y_dash)","metadata":{"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"code","source":"dd.shape","metadata":{"trusted":true},"execution_count":118,"outputs":[{"execution_count":118,"output_type":"execute_result","data":{"text/plain":"(60000, 785)"},"metadata":{}}]},{"cell_type":"code","source":"x_dash = torch.from_numpy(dd.iloc[:,1:].values)\n\nx_dash[0]","metadata":{"trusted":true},"execution_count":131,"outputs":[{"execution_count":131,"output_type":"execute_result","data":{"text/plain":"tensor([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,  18.,  18.,  18.,\n        126., 136., 175.,  26., 166., 255., 247., 127.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  30.,  36.,  94., 154.,\n        170., 253., 253., 253., 253., 253., 225., 172., 253., 242., 195.,  64.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  49.,\n        238., 253., 253., 253., 253., 253., 253., 253., 253., 251.,  93.,  82.,\n         82.,  56.,  39.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,  18., 219., 253., 253., 253., 253., 253., 198., 182.,\n        247., 241.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107., 253.,\n        253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,  14.,   1., 154., 253.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0., 139., 253., 190.,   2.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  11.,\n        190., 253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  81., 240., 253.,\n        253., 119.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,  45., 186., 253., 253., 150.,  27.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,  16.,  93., 252., 253., 187.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0., 249., 253., 249.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,  39., 148., 229., 253., 253., 253., 250., 182.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,  24., 114., 221., 253., 253., 253.,\n        253., 201.,  78.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  23.,  66., 213., 253.,\n        253., 253., 253., 198.,  81.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  18., 171.,\n        219., 253., 253., 253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n         55., 172., 226., 253., 253., 253., 253., 244., 133.,  11.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135., 132.,  16.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          0.,   0.,   0.,   0.], dtype=torch.float64)"},"metadata":{}}]},{"cell_type":"code","source":"type(x_dash)","metadata":{"trusted":true},"execution_count":132,"outputs":[{"execution_count":132,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"code","source":"x_d = x_dash.reshape(x_dash.size(0), 1, 28,28)\nx_d.shape","metadata":{"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"torch.Size([60000, 1, 28, 28])"},"metadata":{}}]},{"cell_type":"markdown","source":"testing over","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nclass MnistDataset(Dataset):\n    def __init__(self, data_path):\n        # data loading\n        df = pd.read_csv(data_path, dtype=np.float)\n        self.x = torch.from_numpy(df.iloc[:,1:].values)\n        \n        self.x = self.x.reshape(self.x.size(0),1,28,28)\n        self.x = self.x.float() # why float?\n        \n        self.y = torch.from_numpy(df.iloc[:,0].values) \n        self.y = self.y.long() # why long?\n        \n        self.n_samples = df.shape[0]\n        \n    def __len__(self):\n        return self.n_samples\n    \n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n        ","metadata":{"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"train_dataset = MnistDataset(\"../input/mnist-in-csv/mnist_train.csv\")\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size,shuffle=True)\n\ntest_dataset = MnistDataset(\"../input/mnist-in-csv/mnist_test.csv\")\ntrain_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size,shuffle=True)\n","metadata":{"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"markdown","source":"We can also look at individual dataset that loaded","metadata":{}},{"cell_type":"code","source":"first = train_dataset[0]\nfeatures, label = first\nprint(features, label)","metadata":{"trusted":true},"execution_count":176,"outputs":[{"name":"stdout","text":"tensor([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   3.,  18.,  18.,  18., 126., 136., 175.,  26., 166., 255.,\n          247., 127.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  30.,  36.,  94.,\n          154., 170., 253., 253., 253., 253., 253., 225., 172., 253., 242.,\n          195.,  64.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253.,\n          253., 253., 253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,\n           39.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,  18., 219., 253., 253.,\n          253., 253., 253., 198., 182., 247., 241.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107.,\n          253., 253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  14.,   1.,\n          154., 253.,  90.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n          139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n           11., 190., 253.,  70.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,  81., 240., 253., 253., 119.,  25.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,  16.,  93., 252., 253., 187.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0., 249., 253., 249.,  64.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,  39., 148., 229., 253., 253., 253., 250., 182.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24.,\n          114., 221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  23.,  66., 213.,\n          253., 253., 253., 253., 198.,  81.,   2.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n          253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,  55., 172., 226., 253., 253., 253., 253.,\n          244., 133.,  11.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135., 132.,\n           16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.],\n         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n            0.,   0.,   0.,   0.,   0.,   0.]]]) tensor(5)\n","output_type":"stream"}]},{"cell_type":"code","source":"type(features)","metadata":{"trusted":true},"execution_count":170,"outputs":[{"execution_count":170,"output_type":"execute_result","data":{"text/plain":"torch.Tensor"},"metadata":{}}]},{"cell_type":"markdown","source":"## initialising the model","metadata":{}},{"cell_type":"code","source":"model = SimpleCNN().to(device=device) # to device?","metadata":{"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"#testing\nx = torch.randn(64,1,28,28).to(device=device)\ny = model(x)\ny.shape","metadata":{"trusted":true},"execution_count":172,"outputs":[{"execution_count":172,"output_type":"execute_result","data":{"text/plain":"torch.Size([64, 10])"},"metadata":{}}]},{"cell_type":"markdown","source":"## Define loss criterion and optimizer","metadata":{}},{"cell_type":"code","source":"loss_criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"markdown","source":"## Train on data","metadata":{}},{"cell_type":"code","source":"current_loss = 0\nfor epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(train_dataloader):\n        # Get data to cuda if possible\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n        \n#         data = data.reshape((data.shape[0],1,28,28))\n#         print(f\"data shape: {data.shape}\")\n\n        # forward\n        scores = model(data)\n        loss = loss_criterion(scores, targets)\n        current_loss = loss\n        \n        # backward\n        optimizer.zero_grad()\n        loss.backward()\n\n        # gradient descent or adam step\n        optimizer.step()\n    \n    print(f\"At epoch: {epoch}, loss: {current_loss}\")","metadata":{"trusted":true},"execution_count":178,"outputs":[{"name":"stdout","text":"At epoch: 0, loss: 23.493770599365234\nAt epoch: 1, loss: 21.50348663330078\nAt epoch: 2, loss: 29.63482666015625\nAt epoch: 3, loss: 25.373334884643555\nAt epoch: 4, loss: 23.500032424926758\n","output_type":"stream"}]},{"cell_type":"code","source":"def check_accuracy(model, dataloader):\n    \n    total_sample = 0\n    correct_sample = 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n        for x, y in dataloader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n#             x = x.reshape(x.shape[0], -1)\n            \n            scores = model(x)\n            _, predictions = scores.max(1)\n            correct_sample = (y==predictions).sum()\n            total_sample += predictions.size(0)\n            \n    model.train()\n    \n    print(f\"out of total sample : {total_sample}  correct sample : {correct_sample} accuracy : {float(correct_sample/total_sample)*100:.2f}\")\n            \n    ","metadata":{"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"check_accuracy(model, train_dataloader)\ncheck_accuracy(model, test_dataloader)","metadata":{"trusted":true},"execution_count":180,"outputs":[{"name":"stdout","text":"out of total sample : 10000  correct sample : 0 accuracy : 0.00\nout of total sample : 10000  correct sample : 1 accuracy : 0.01\n","output_type":"stream"}]}]}